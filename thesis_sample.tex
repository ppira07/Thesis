\documentclass[11pt,a4j]{jsarticle}

%本ファイル使用パッケージ
\usepackage{graphicx}

%卒論スタイルファイル
\usepackage{sty/ib_thesis}

%TeX数式用
%\usepackage{amsmath}
\usepackage{ascmac}
%\usepackage{graphix}

%argmax定義
\newcommand{\argmax}{\mathop{\rm arg~max}\limits}

%コメントアウト
\usepackage{comment}

%表紙パラメータ設定
%
\author{平野 万由子}     %本人名
\supervisor{萩原 信吾} %指導教員名
\fyear{27}             %所属年度
\submit{28}{1}{31}    %提出和暦，月，日
\title{ナイーブベイズ分類を用いた文の感情推定と顔文字自動付与システムの提案} %論文タイトル


%ドキュメントスタート
\begin{document}
 \pagestyle{empty}
 \clearpage

 %表紙の生成
 \maketitle

 %アブストラクトはもし中国文字・朝鮮文字が必要なら，WORDで書く(中・朝文字をだすのはめんどい)
 %英語でよければ次のように

 %日本語アブストラクト
 \jabstract{
近年、インターネットの普及により、多くのユーザが SNS (Social Networking Service)を利用している。
SNS では、テキストベースのやりとりが常套化しており、さらに簡潔な短文でやりとりをするチャット形式のコミュニケーションツールを利用するユーザが増加している。
しかし、テキストベースのやりとりでは、音声や表情といった非言語情報が欠落しがちである。
そのため、テキストの書き手と読み手の間に認識の齟齬が発生する。
そこで本研究では、インターネット上のテキストの感情を推定し、テキストの感情を補助するための顔文字を付与するシステムを提案する。
感情の推定では、感情語辞書を用いて品詞単位に感情を推定し、ナイーブベイズ分類器を用いて感情のスコアを算出する。
算出した感情のスコアを元に、顔文字辞書を用いて、推定した文の感情に見合った顔文字を付与する。
本研究では、顔文字を`喜'、`悲'、`驚'、`不安'、`期待'、`怒'、`平静'の7感情に分類した。}

 %英語アブストラクト
 \eabstract{Many users are resently using SNS (Social Networking Service).
In SNS, text-based exchange has been normalized. 
Furthermore, users who are using communication tools of a chat form exchanging concise and short sentences has been increasing.
Nevertheless in the exchange of the text-based messages, the non-language information such as a sound and facial expression are inclined to lack.
Therefore, disagreement of the recognition occationaly occurs among writers and readers of the message.
This study propose the system which estimates the feeling of sentences, and gives an emoticon to support the feeling of the sentences in the Internet.
To estimate feeling, divide sentence into a unit of part of speech using emotional words dictionary, calculate feeling score by naivebayes classifier.
Based on the result of calculated score, gives an emoticon which is suitable to the feeling of sentence by using emoticon dictionary.
In this study, divide the emoticons into 7 feelings as `happiness', `sadness', `surprized', `anxienty', `expectation', `anger' and `sereneness'.}

 %アブストラクトページの作成
 \makeabstract
 \newpage
 
 %目次の生成
 \tableofcontents
 \newpage
 
 %ここからページ数1
 \pagestyle{plain}
 \setcounter{page}{1}
 
 
 %本文
\section{はじめに}\label{sec:begin}
 現在、Social Networking Service(SNS)の普及により多くのユーザーがSNSを利用している。
SNSとは、人と人とのコミュニケーションをインターネットを通してサポートするコミュニティ型の会員制 Web サービスのことである。
これには、チャットやLINE\raisebox{.5zw}{\scalebox{.5}{\textregistered}}のような書き手がやりとりの速さを求めるサービスや、Twitter\raisebox{.5zw}{\scalebox{.5}{\textregistered}}のような短文でやりとりするサービスがある。

このようなインターネットを介してのコミュニケーションでは、書き手の感情を読み取れるテキストと、読み取ることができないテキストがある。
例えば、「上司に褒められて嬉しかった」と「後で君に話したいことがある」では、後者の感情を読み取ることが難しい。
このような文から書き手の感情を取得することができれば、そこからコミュニケーションをとる上で得られる情報は大きい。

テキストから感情を抽出することを、「感情推定」という。
具体的には、感情推定は、文中に表現されている感情を、自然言語処理により判別することと言える。
この感情推定はインターネット上の書類を扱うための主要な技術の一つになっている。
例えば、レビュー記事から商品・サービスに対する感情を抽出することにより、消費者の情報収集・企業の市場調査が可能となる。
また、テキスト読み上げロボットの表情・ジェスチャー構成へと幅広い応用が考えられる\ibcite{suga}。

この感情推定にはいくつかの手法が存在する。
基本的な手法として挙げられるのは、感情語辞書を使用する方法である。
この感情語辞書とは、語彙とその語彙が表す感情を記録したものである。
この手法ではその感情語辞書を使用して、与えられた文について語彙単位で感情を評価し、その文全体の感情を判定する。

次に挙げられる手法は、感情コーパスを使用する手法である。
感情コーパスとは、文に感情を付与したコーパスである。
感情推定に関する研究には、感情コーパスを用いて文単位に感情を抽出する方法や、感情語辞書を用いて品詞単位に感情を推定し、構文・形態素解析を行って感情のスコアを算出する方法がある。
この手法には、コーパスを学習データとして Support Vector Machine (SVM)やナイーブベイズ分類器を使用し、単語の出現頻度から対象文の感情値を出力する研究がある ~\ibcite{yamamoto}。
また、その感情コーパスの作成には、コーパス内の文章をそれぞれ人手でタグ付けする方法や、あらかじでシソーラスや辞書から感情に関係する語を分類して半自動でコーパスを作る方法 ~\ibcite{matsumoto} がある。
本研究では、感情コーパスを用いて文単位に感情を抽出する手法を用いる。

感情コーパスを用いた感情推定は、ナイーブベイズ分類器を使用して感情属性をタグ付けされた文に対する感情語の出現頻度を計算することによって行う。
ナイーブベイズ分類器のモデルには、多項モデルと多変数ベルヌーイモデルがある。
多項モデルでは文書の各位置でどの単語が起こったかをモデル化しているのに対し、多変数ベルヌーイモデルは各単語が起こったか起こらなかったかをモデル化している。
そのため、多項モデルはテキスト分類において多変数ベルヌーイモデルより性能が高いことが明らかになっている\ibcite{andrew} \ibcite{suzuki}。

また、近年では、文末に顔文字を付与して文の感情を表すユーザが多い。
顔文字を付与することで、インターネット上のコミュニケーションを円滑にすることができる。
顔文字は、\verb|(^_^)|のように、記号や文字を組み合わせて表情を表現したものである。
このように正位置で顔を表現することは、主に日本で使用される顔文字の特徴であり、これを東洋式顔文字と呼ぶ。
顔文字には文の感情を強調、補足できるという利点があるが、顔文字の種類は増大し続けているため、ユーザが文に適切な顔文字をただ1つ選ぶことは難しい。
この問題に対して、江村らはユーザの入力文から感情を推定し、顔文字を推薦するシステムを提案した\ibcite{emura}。


本研究では、感情コーパスを用いて多項モデルでナイーブベイズ分類を行う。そして、顔文字付き感情語辞書を構築する。構築した辞書をもとに、入力文の感情を推定し、推定した感情に適切な顔文字を推薦することが目的である。

本研究の構成は以下の通りである。
\sref{sec:begin} では、本研究の背景及び目的を記述した。\sref{sec:relatedworks} では、本研究を行うにあたって参考にした文献・研究を説明する。
\sref{sec:def} では、本研究で構築した確率付き感情語辞書と顔文字付き感情確率辞書の定義と、これらを構築する際に使用したナイーブベイズ分類器ついて説明する。
\sref{sec:experiment}では、精度検証実験の手順とその結果を記述する。
\sref{sec:analyze}では、\sref{sec:experiment} で行った実験結果をもとに考察を行う。
\sref{sec:summary}では、本研究の成果と今後の展望を述べる。

\section{感情抽出に関する研究}\label{sec:relatedworks}
人間は、日常的に日本語や英語、手話などの自然言語を用いて意思疎通を行う。
自然言語とは、音素、形態素、語、文、文章という階層構造を持っている。
自然言語は、人間の意思疎通手段として自然発生的に構築されたため、人間は自然言語を直感的に理解できる。
しかし、コンピュータで処理を行うためには、自然言語処理を行う必要がある。
この自然言語処理とは、自然言語を機械的に処理するための要素技術およびその応用を含む技術分野である。

本研究では、この自然言語処理の技術を用いて文の感情抽出を行う。
感情抽出とは、テキストの書き手の感情を判別する研究である。
感情抽出に関する研究には、感情コーパスを用いて文単位に感情を抽出する方法や、感情語辞書を用いて品詞単位に感情を抽出し、形態素解析を行って感情のスコアを算出する方法がある。
感情コーパスとは、文章にその書き手の感情を表す感情タグを付与したコーパスである。
感情コーパス中の文と入力文の類似度を算出することによって感情抽出ができる。
また、感情語辞書とは、形容詞や動詞などの一般品詞に感情の尺度を付与した辞書である。
そして、形態素解析とは、文を形態素と呼ばれる意味のある最小単位に分割し、辞書を利用してそれぞれの品詞や内容を判別することである。
形態素解析はコンピュータによる自然言語処理の基礎技術の一つであり、かな漢字変換や機械翻訳、音声認識で使用される。
入力文を形態素解析し、感情語辞書を参照して入力文の感情を抽出することができる。

感情抽出の従来研究では、単語に感情をタグ付けしてまとめた感情語辞書をもとにテキストから感情を推定するものが多くある。
感情を推定する基準となる感情語については、生起事象文型パターン \ibcite{matsu} に基づいた会話文からの感情推定方法で定義されている。
この感情語とは、単体で感情を表現することが可能な単語である。
例えば、名詞であれば「楽しみ」や「がっかり」、動詞であれば「驚いた」や「怒る」などである。
感情語にはこのような感情の種別を表す。
感情属性のほかに感情属性値と感情パラメータが付与されている。
この感情属性値とは、単語がその感情属性にどれだけ帰属するかの度合いを表す。
感情パラメータとは、文中の各要素に付与された感情属性値を感情の種類ごとに合成したものを指す。
感情パラメータは、$(各感情属性の数) * (文中の格要素数 +1)$ の感情ベクトルで表現する。

感情コーパスによる感情抽出の手法には、菅原の研究がある\ibcite{suga}。
これは、まずコーパスを学習データとして、SVMやナイーブベイズ分類器を使用する。
そして、感情がタグ付けされた文において単語の出現頻度を算出する。
これにより対象文の感情を出力する。

感情コーパスの作成には、松本らが提案したコーパス内の文章をそれぞれ人手でタグ付けする方法や、シソーラスや辞書から感情に関係する語を分類して半自動でコーパスを作る方法がある。
また、テキストをuni-gram、bi-gram、tri-gram の三つの分割方法で感情推定し、感情が全て一致した文と感情を感情コーパスに追加することで感情コーパスを半自動的に構築する研究がされている~\ibcite{funane}。
この研究の結果、構築されたコーパスによる感情推定精度は 72.1 \% であった。

本研究では、テキストを形態素解析し、それぞれの形態素に感情属性と感情属性値を与えて感情語辞書を作成する。
この感情語辞書は、舟根による研究で半自動生成されたコーパスを元に作成する。
このとき、感情語の感情属性値はナイーブベイズ推定によって算出する。
そして、構築した感情語辞書をもとにして文の感情を推定する。

%\subsection{顔文字解析の研究}\label{sec:kaomojichushutsu}

\section{ベイズ推定と感情推定}\label{sec:def}
本研究では、文の感情感情推定についてベイズ推定を用いている。
そこで、\ssref{sec:defbayes}では、ベイズ推定とベイズの定理を説明する。
\ssref{sec:defnaivebayes}では、本研究で用いたナイーブベイズ分類について説明する。

  \subsection{ベイズ推定とは}\label{sec:defbayes}
ベイズ推定とは、ベイズ確率に基づき観測事象から推定したい事象を確率的に推論する手法である。
ベイズ推定の基本的な方法論となっているベイズの定理は、18世紀にイギリスの確率論研究家トーマス・ベイズが提案した。
ベイズ確率は、ベイズの定理を用いて複数の命題の各々のもっともらしさを確率値で表したものである。
ベイズの定理は統計学に応用され、ベイズ統計学の代表的な方法となっている。
ベイズ推定には膨大な反復計算が必要となるが、コンピュータの処理性能が向上したことにより、現在は心理学や経済学にも応用されている。

ベイズの定理は、以下の等式で表される。

\[
P(B|A)=\frac{P(A \cap B)}{P(A)}=\frac{P(A|B)P(B)}{P(A)}
\]


$P(A)$、$P(B)$は事象$A$、$B$が発生する確率である。
$P(B)$は$P(A)$が起きる前の事象$B$の確率であり、これは事前確率と呼ばれる。
$P(B|A)$は事象$A$が発生したあとに事象$B$が発生する条件付き確率を表す。これを$B$事後確率と呼ぶ。
$P(A|B)$は事象$B$が発生したあとの事象$A$が発生する条件付き確率を表す。これは$B$が真の際にデータが得られる尤度を表し、尤度関数と呼ばれる。
$P(A \cap B)$は事象$A$が発生し、事象$B$も発生する確率を表す。
この式から、事後確率$P(B|A)$は事前確率$P(B)$と尤度$P(A|B)$の積に比例することが分かる。



\begin{equation}
P(B|A)=\frac{P(A|B)P(B)}{P(A)}
\end{equation}

において、両辺に$P(A)$を掛けると

\begin{equation}
P(A) \cdot P(B|A)=P(B) \cdot P(A|B)
\end{equation}

となる。

また、全体集合を$U$としたとき、

\begin{eqnarray*}
P(A) = \frac{A}{U}\\
P(B) = \frac{B}{U}
\end{eqnarray*}

となる。

\begin{eqnarray*}
P(A|B) & = & \frac{A \cap B}{B}\\
P(B|A) & = & \frac{B \cap A}{A}
\end{eqnarray*}

であるから、

\begin{eqnarray*}
P(A) \cdot P(B|A) & = & \frac{A}{U} \cdot \frac{A \cap B}{A}\\
               & = & \frac{A \cap B}{U}\\
P(B) \cdot P(A|B)  & = &\frac{B}{U} \cdot \frac{B \cap A}{B}\\
                  & = & \frac{B \cap A}{B}
\end{eqnarray*}

となる。

したがって、

\[ P(A) \cdot P(B|A)=P(B) \cdot P(A|B) \]

が成立する。

ベイズ推定には、サンプル数が少ない場合やモデルが複雑である場合にも推定が可能であるというメリットがある。

 \subsection{ナイーブベイズ分類}\label{sec:defnaivebayes}
ナイーブベイズ分類は、過去の事例をもとに未知の文書があらかじめ与えられている場合にどのカテゴリに属するかを決定する分類手法である。
未知の文書に対して事後確率が最大となるクラスを出力することで分類を行う。
ナイーブベイズ分類においては、単語間の相関関係を考慮せず、単語の出現確率のみを学習させればよいので、実装が容易で、さらに学習時間も短いことが特徴である。
また、有効な特徴を用いることで高い分類精度が得られる。
ナイーブベイズ分類は、現在 e-Learning システムや SPAM フィルタに利用されている。

次に、ナイーブベイズ分類の数式について説明する。
ナイーブベイズは、ベイズの定理の数式を用いて分類を行う。
まず、コーパスの1文を文$s$とみなす。
文$s$はいくつかの単語$w_1,w_2, \cdots ,w_j$で構成されている。
各感情カテゴリを$c_1,c_2 \cdots ,c_i$とする。

事後確率$P(c_i|s_j)$は、以下の数式で求められる。

\[
P(c_i|s_j)=\frac{P(c_i|w_1,w_2, \cdots ,w_j)}{P(c_i)}=\frac{P(w_1,w_2, \cdots ,w_j|c_i)P(c_i)}{P(c_i)} \propto P(w_1,w_2, \cdots ,w_j|c_i)
\]

上式は$P(w_1,w_2, \cdots ,w_j|c_i)$に比例するため、$P(c_i)$は無視することができる。
また、ナイーブベイズでは各感情カテゴリのもとで単語は独立に生起すると仮定するため、感情カテゴリにおける単語の出現確率は $P(w_k|c_i)$ で求められる。よって、$P(w_1,w_2, \cdots ,w_j|c_i)$はその積で求めることができるため、$P(w_1,w_2, \cdots ,w_j|c_i)$は以下の式で表される。

\[
P(w_1,w_2, \cdots ,w_j|c_i)=\prod_{k=1}P(w_k|c_i)
\]


したがって、文$s_j$の事後確率$P(c_i|s_j)$は以下のように求めることができる。

\[
P(c_i|s_j)=P(c_i)\prod_{k=1}P(w_k|c_i)
\]

このとき、$P(c_i)$ はカテゴリ$c_i$ が得られる確率であり、これは以下のように表すことができる。

\[
P(c_i)=\frac{カテゴリc_i と判定された文の数}{すべてのカテゴリの全文数}
\]

また、ある単語 $w_k$ が感情カテゴリ $c_i$ に出現する確率$P(w_k|c_i)$は以下のように表すことができる

\[
P(w_k|c_i)=\frac{単語 w_k が出現する回数}{感情カテゴリに含まれる全単語数}
\]

その結果、$P(c_i|s_j)$ 文$s_j$ が与えられた時にカテゴリ$c_i$ が得られる確率は、以下のように表すことができる。

\[
P(c_i|s_j)=\frac{カテゴリc_i に属する文の数}{コーパスに含まれる全文数}
\]

これにより、単語$w_j$が出現した際、$w_j$がカテゴリ$c_i$に属する確率を求めることができる。


  \subsection{本研究で用いるナイーブベイズ分類}\label{sec:thesisnaivebayes}
本研究では、舟根の研究で生成された感情コーパスをもとに、確率付き感情語辞書を生成する。
その後、Twitter から収集した 12 万件の tweet をもとに、tweet の文中に付与された顔文字を用いて顔文字付き感情確率辞書を生成する。
これらを生成する際、感情属性値を算出するためにナイーブベイズ分類を用いる。


まず、分類単位であるコーパス中の1文を文$s$とする。文$s$はいくつかの単語$w_1,w_2, \cdots ,w_j$で構成されている。
各感情カテゴリを $c_1,c_2 \cdots ,c_7$とすると、$s_j$が分類されるべき感情属性は、$P(c_i|s_j)$を最大化するような感情となる。
これは、ナイーブベイズ分類から以下の式表すことができる。

\begin{eqnarray*}
c & = & {c_1,c_2 \cdots ,c_7}\\
\hat{c} & = & \argmax_{c} P(c_i|s_j) \\
        & = & \argmax_{c} P(c_i|w_1,w_2,\cdots ,w_k) \\
        & = & \argmax_{c} P(w_1,w_2,\cdots ,w_k|c_i)P(c_i) \\
\end{eqnarray*}

文の分類には次式を最大化する感情属性$\hat{c}$を選ぶべきであるため、

\[
\hat{c}=\argmax_{c_i} P(c_i)\prod_{k=1}^n P(w_k|c_i)
\]

のようにして各単語の感情属性値の積となる最大値$\hat{e}$を求める。

$P(w_j|e_i)$は以下のように表すことができる。

\[
P(w_j|e_i)=\frac{感情 e_i とタグ付けされた全ての文で形態素 w_j が出現する回数}{感情 e_i とタグ付けされた全ての文の形態素の数}
\]

これにより、文中の形態素 $w_i$が出現した際に、感情$e_1,e_2, \cdots ,e_7$にそれぞれどのくらい帰属するかを求めることができる。

\subsubsection{ゼロ頻度問題}\label{sec:zero}
未知の単語$W_\mathit{new}$が出現した場合、$W_\mathit{new}$ の出現確率 $P(W_\mathit{new}|C)$ は0と推定される。
$P(W_\mathit{new}|C)$ は複数の単語例の確率の積から算出する。

以下に数式を示す。

\[
P(W_\mathit{new}|C)=\frac{単語 W_\mathit{new} の数}{カテゴリC の語彙数}
\]

この場合文中のどれか1つの単語の確率が0だと、文全体の確率も0となってしまう問題が発生する。
この問題を、ゼロ頻度問題と呼ぶ。

この問題を避けるために、$W_\mathit{new}$の出現確率を求める際に、単語の出現回数を補正した値を用いるスムージングが行われる~\ibcite{textmining}。

スムージングは以下の様に行われる。

\[
P(W_\mathit{new}|C)=\frac{単語 W_\mathit{new} の数 + \alpha }{カテゴリC の語彙数 + \alpha }
\]

一定の数を予め加えておくことで、未知の単語$W_\mathit{new}$が出現した場合に確率を0にさせないことができる。

ここでは単純な加算方であるラプラス法を用いてスムージングを行う。
これはラプラススムージングと呼ばれる。

ラプラススムージングでは、加算法において単語の出現頻度を求める際に全ての単語の出現回数に $\alpha=1$ を加える手法である。
 
\section{感情推定における自然言語処理の基礎技術}
\subsection{Twitter API}
 Twitter API とは、Twitter 社が無料で提供する API サービスのことである。
API とは、Application Programming Interface のことであり、あるソフトウェアの機能や管理するデータなどを、外部の他のプログラムから呼び出して利用するための手順やデータ形式のことである。
Twitter API を利用することで、ウェブサイトやアプリなどから Twitter の機能を呼び出したり、Twitter の投稿文の編集や参照、検索などをプログラム上で扱うことができる。

Twitter API には、REST API と Streaming API の二種類がある。

REST API は、HTTP 接続をその都度行うことで、蓄積された過去の Tweet 情報の取得や Tweet の投稿、ユーザ情報の変更などをプログラム上で行うことができる基本的な API である。
通常の Twitter クライアントや BOT で利用される。
REST API は URL に要求などを定められた形式で文字列にしたクエリを渡し、そのレスポンスを取得する REST(Representational State Transfer) を利用している。
REST API は利用規制があり、一定時間ごとにAPI の呼び出せる回数が制限されている。
そのため、制限数を使い切ってしまった場合、API の呼び出しが一定時間できなくなる。
API 1.1 では15分間にアプリごと・API ごとにそれぞれ呼び出しの制限回数が定められている。

Streaming API は一度接続すると HTTP 接続を保ったまま、接続が切断されるまで Tweet 情報を取得し続けることができる API である。
そのため、タイムラインの変更をリアルタイムに受け取ることができる。
Streaming API はデータ解析などで大量の Tweet 文を必要とする開発者向けの API である。
仕組みとしては、REST API と同じく REST でアクセスを行う。
しかし、タイムラインの更新が発生するまでレスポンスを保留させるとこで、高い瞬時性を実現している。
一度に何本も API を接続することができない点や、切断と接続を短時間に連続で行うことができない点、過去の Tweet 文を取得できないなどの制約がある。
しかし、REST API とは違い、API の利用規制がかからないという利点がある。

本研究では、顔文字や文章の感情推定について、ナイーブベイズを使用している。この場合、ベイズ推定の推定確率の確からしさを大きくするためには、その確率を計算するためのベースとなるコーパスの量が重要となる。このコーパスとは、ある目的において無作為に集められた多量なテキストのことを言い、本研究で必要となるコーパスはすなわち、1) 文章より感情推定が容易なテキスト 2) 顔文字が使用されているテキスト、これら二つの条件を充すような大量のテキストである。

このTweeterAPIでは次のような機能を持っている。

本研究では Streeming API を使用し、リアルタイムに Tweet 文の取得を行った。その結果、約12万件の Tweet 文を取得した。

\subsection{MeCab と Natto}
\subsubsection{形態素解析}
形態素解析 (Morphological Analysis) とは、自然言語処理の手法の一つである。
ある文章やフレーズを、意味を持つ最小限の単位である形態素に分解し、辞書を利用してその文章やフレーズの品詞や内容を判断するために用いられる。
形態素解析は現在、かな漢字変換や機械翻訳、音声認識で使用されている。

例文「私は家で勉強します」を形態素解析すると、「私/は/家/で/勉強/し/ます」と分割することができる。

\subsubsection{MeCab と Natto}
本研究では、形態素解析に MeCab と Natto を使用した。
まず、Mecab について述べる。
MeCab \ibcite{mecab} は、奈良先端科学技術大学院大学が開発したオープンソースの形態素解析エンジンである。
MeCab は単体では機能せず、形態素ごとに分割するためには品詞や意味が内蔵された辞書が必要になる。
MeCab 用の基本的な辞書として IPA 辞書や Juman 辞書、Unidic 辞書がある。
これらの基本的な辞書を使うことはもちろん、自分で任意の単語を手動で辞書に追加することも可能である。
また、ユーザが開発した様々なオリジナル辞書も Web 上に存在する。
本研究では、IPA 辞書を使った MeCab で形態素解析を行う。

MeCab を用いて例文「私は家で勉強します」を形態素解析すると、以下のような結果が得られる。

\begin{itembox}[l]
私  名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\\
は  助詞,係助詞,*,*,*,*,は,ハ,ワ\\
家  名詞,一般,*,*,*,*,家,イエ,イエ\\
で  助詞,格助詞,一般,*,*,*,で,デ,デ\\
勉強  名詞,サ変接続,*,*,*,*,勉強,ベンキョウ,ベンキョー\\
し  動詞,自立,*,*,サ変・スル,連用形,する,シ,シ\\
ます  助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\\
EOS
\end{itembox}

上に示したように、MeCab は CSV (Commma Separated Value) 形式になっている。
MeCab の出力フォーマットは、左から、表層形、品詞、品詞細分類1、品詞細分類2、品詞細分類3、活用形、活用型、原形、読み、発音となっている。

本研究では、MeCab を利用するために、Natto という Gem パッケージを使用した。
Gem パッケージは、プログラミング言語 Ruby で使用されるライブラリやアプリケーションのパッケージである。
Natto の他にも多くのライブラリが Gem 形式でパッケージされて公開されている。

Natto を用いることで、Ruby で簡単に MeCab を呼び出すことができる。
例えば、「今日は学校を休みたい」という文を MeCab を用いて形態素解析するとき、以下のようにプログラムを書く。

\newpage

\begin{verbatim}
#natto.rb

require 'natto'

text = '今日は学校を休みたい'

nm = Natto::MeCab.new
nm.parse(text) do |n|
  puts "#{n.surface} #{n.feature}"
end
\end{verbatim}

上記のプログラムを実行すると、以下のように表示される。

\begin{itembox}[l]{プログラムの例}
  今日  名詞,副詞可能,*,*,*,*,今日,キョウ,キョー \\
  は  助詞,係助詞,*,*,*,*,は,ハ,ワ\\ 
  学校  名詞,一般,*,*,*,*,学校,ガッコウ,ガッコー\\
  を  助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\\
  休み  動詞,自立,*,*,五段・マ行,連用形,休む,ヤスミ,ヤスミ\\
  たい  助動詞,*,*,*,特殊・タイ,基本形,たい,タイ,タイ\\
 BOS/EOS,*,*,*,*,*,*,*,*\\
\end{itembox}

本研究では、Natto を用いて文の形態素解析を行う。

\section{顔文字推定システム}\label{sec:theorem}
  \subsection{コーパスを用いた確率付き感情語辞書の作成}\label{sec:tweetcorpus}
本研究では、舟根の感情コーパスを用いて確率付き感情語辞書を作成した。
この感情コーパスの精度は 98\% であった。
これは、N-gram でそれぞれ分割し、uni-gram、bi-gram、tri-gram の感情が一致したものを感情コーパスに登録している。
N-gram とは、あるテキストの総数を前から順に任意の N 個の文字列または単語の組み合わせで分割したものである。
N 個の数 (gram) によって、それぞれ「 uni(1)-gram, bi(2)-gram, tri(3)-gram, \cdots 」と呼ばれる。
本研究では、形態素はそれぞれ独立していると考えるため、uni-gram で感情を抽出し作成した感情コーパスを使用する。
感情語コーパスの例を以下に示す。

\begin{table}[htb]
  \caption{感情コーパスの例}
  \centering
  \begin{tabular}{c|c} \hline
    文 & 感情属性 \\ \hline \hline
    とても楽しい1日だった。 & 喜 \\
    指輪をなくしてしまった & 悲 \\
    この会社、むかつきます。 & 怒 \\ 
    安さに衝撃を受けました。 & 驚 \\
    ちゃんと届くか心配です。 & 不安 \\
    家に届くのが楽しみです。 & 期待 \\
    夫へのプレゼントに購入。& 平静 \\ \hline
  \end{tabular}
\end{table}

まず、感情コーパスを MeCab を用いて形態素解析した。
次に、ナイーブベイズ分類を用いて感情語 $w_j$ が感情属性 $e_i$ で出現する確率 $P(w_j|e_i)$ を算出した。
これを感情確率と呼ぶ。
この際用いた感情語には、動詞、名詞、形容詞、感動詞を用いた。
なお、MeCab を用いて形態素解析した結果の形態素の表層形では活用形が出力されているため、形態素の原型を感情語とした。
感情属性 $e_i$ に感情語 $w_j$ が出現する感情確率 $P(w_j|e_i)$ を求める数式を以下に示す。

\[
P(w_j|e_i)=\frac{感情 e_i とタグ付けされた全ての文で形態素 w_j が出現する回数 +1}{感情 e_i とタグ付けされた全ての文の形態素の数 + コーパスに含まれる形態素数}
\]

最後に、抽出した形態素、感情属性、感情確率を確率付き感情語辞書に登録した。

  \subsection{顔文字付き感情確率辞書の作成}\label{sec:kaomojidic}
Twitter API を用いて収集した tweet をもとに、顔文字付き感情確率辞書を作成した。
顔文字付き感情確率辞書とは、\ssref{sec:tweetcorpus}で作成した確率付き感情語辞書に、tweet の文中に出現する顔文字を付与した辞書である。

まず、収集した tweet を、確率付き感情語辞書を用いて形態素解析した。
tweet 文を $s_i$、それに含まれる形態素を $w^i_k$、顔文字を $f^i$ とする。
この際、tweet の文中に出現する括弧で囲まれている、漢字、ひらがな、カタカナ、数字以外の文字列を顔文字とした。
形態素解析の結果を以下の数式に示す。

\[
s_i=w^i_1,w^i_2,\ldots,w_n^i,f^i
\]

本研究で用いる感情は、`喜'、`悲'、`怒'、`驚'、`期待'、`不安'、`平静'の7感情である。
これらの7感情を$e_1, e_2, \ldots, e_7$ と表す。

tweet 文 $s_i$ の感情推定のため、以下のような表を生成する。

\begin{eqnarray*}
  \begin{array}{r|ccc|l}
        & w^i_1              & \ldots          & w^{i}_{k}    & 感情確率 \\ \hline
    e_1 & P(e_1|w^i_1) &                 & P(e_1|w^i_k) & \prod_{s=1}^{k}P(e_1|w^i_s) \doteq P^i_{e_1}\\
    \vdots             &                 & \ddots       &                                           & \\
    e_7 & P(e_7|w^i_1) &                 & P(e_7|w^i_k) & \prod_{s=1}^{k}P(e_7|w^i_s) \doteq P^i_{e_7}\\
  \end{array}
\end{eqnarray*}


このとき、$P(e_1|w^i_1)$ は 確率付き感情語辞書に登録された感情確率を用いる。
また、$\prod_{s=1}^{k}P(e_1|w^i_s)$ は、感情属性 $e_i$ に対する全感情語の感情確率を乗算した値である。
この値を、顔文字感情確率ベクトルと呼ぶ。
そして、全ての感情属性のうち $\prod_{s=1}^{k}P(e_1|w^i_s)$ の値が最も大きい感情属性を顔文字 $f_i$ の感情属性とする。
最後に、顔文字、推定された感情属性、その感情属性の感情確率、顔文字感情確率ベクトルを、以下のように顔文字付き顔文字辞書に登録する。

\begin{eqnarray*}
  \left\{
   \begin{array}{c}
     f^i, e_s, P^i_{e_s}, (P^i_{e_1}, P^i_{e_2}, \ldots, P^i_{e_7})\\
     \vdots \\
     f^j, e_{s'}, P^j_{e_{s'}}, (P^j_{e_1}, P^j_{e_2}, \ldots, P^j_{e_7})\\
   \end{array}
  \right\}
\end{eqnarray*}


これをもとに作成した顔文字付き感情確率辞書の例を以下に示す。

\begin{itembox}[l]{顔文字付き感情確率辞書の例}
\verb|(^○^)|,喜,6.074e-116,6.074e-116,3.0684e-118,1.376e-119,1.493e-118,1.380e-118,9.310e-120,6.543e-125\\
\verb|(；▽；)|,悲,2.093e-182,8.68e-185,2.093e-182,6.725e-187,1.920e-186,2.223e-186,1.52e-185,1.587e-202\\
\verb|(´・ω・`)|,不安,4.031e-08,3.044e-08,3.472e-08,1.731e-08,1.731e-08,2.699e-08,4.031e-08,1.731e-08\\
\end{itembox}

\subsection{入力文の感情推定}
\ssref{sec:tweetcorpus}で作成した確率付き感情語辞書と、\ssref{sec:kaomojidic}で作成した顔文字付き確率感情語辞書を用いて入力文の感情推定を行い、その文の感情に適切な顔文字を文末に付与するシステムを構築した。
このシステムを顔文字推薦システムと呼ぶ。

顔文字推薦システムの流れを以下に示す。

\begin{itemize}
  \item
    入力文を形態素解析する。
  \item
    出力された形態素(動詞、名詞、形容詞、感動詞)のうち、最も感情確率が高い形態素を、確率付き感情語辞書を参照して取り出す。
  \item
    確率付き感情語辞書と顔文字付き確率感情語辞書の感情ベクトルのハミング距離を計算する。
  \item
    ハミング距離が最も小さい顔文字を入力文の文末に付与する。この際、ハミング距離が同等の顔文字が複数個あった場合には、顔文字をランダムに取り出す。
\end{itemize}

%WIP
このとき、出力された感情に対応する顔文字は、顔文字付き感情確率辞書に多く登録されている。
このなかで最もツイートに適切な顔文字を選ぶとき、ハミング距離 (Hamming distance) を用いる。
ハミング距離とは、任意の2つの値を比較したときに値が異なっているビット数の割合である。
本研究では、確率付き感情語辞書を用いて入力文の形態素の感情ベクトルを算出し、顔文字付き確率辞書中の感情ベクトルとのハミング距離が最も小さい顔文字を入力文の文末に付与する。
$f$ を顔文字、$a$ を顔文字付き確率辞書の感情ベクトル、$b$ を入力文の感情ベクトルとしたとき、ハミング距離は以下のように計算する。

\[
  f=\sum_{i=1}^{n} |a_i-b_i|
\]

  \subsection{考察}
舟根の感情コーパスから顔文字付き確率辞書をした。その結果、顔文字に感情属性と感情確率を付与することができた。
しかし、"\verb|(´・ω・`)|,喜" や、"\verb|(^ω^)|,悲"など、顔文字に適切ではない感情属性が付与されていることがある。
この原因は、書き手の故意によって、tweet 文中の感情と顔文字が一致させられていないからだと考える。

  \subsection{ \ssref{sec:theorem}のまとめ}
\ssref{sec:theorem}では、顔文字推薦システムを構築した。

\section{実験}\label{sec:experiment}
   %手順と条件の説明
本研究で構築した顔文字推薦システムの精度を検証するため、被験者に感情が生起している文章を入力してもらった。
これを被験者5名に1つの感情カテゴリについて5文ずつ、7感情分を入力してもらい、計175文で実験を行った。
入力文に対して推薦された顔文字が適切であれば正解、適切でなければ不正解とし、正解率を求めた。
この正解率を感情推薦システムの精度とする。
精度の計算は、各感情カテゴリごとに、入力文に対して出力された顔文字が適切であると判断された割合の乗数を求めた。
さらに、全カテゴリ分の乗数を掛け合わせ、顔文字推薦システムの精度とした。
各入力文とその正解感情の例を以下に示す。

\begin{itembox}[l]{正解感情付きの入力文の例}
昨日のラーメンがおいしかった。 喜 \\
高級豆安く手に入って嬉しい！ 喜\\
チャーシューが柔らかかった。 喜\\
この年になると二日酔いが辛い。 悲\\
この服はあまりかわいくない。 悲\\
カフェのランチじゃ物足りない。 悲\\
届いた靴が意外と大きかった…。 悲\\
東京の物件どれも高い。 怒\\
高速バスは危ない！ 怒\\
安い物件はよくないのばかり。 怒\\
卒論がめんどくさい！ 怒\\
Amazon Prime Now で注文したら本当に1時間で届いた！ 驚\\
電車が5分に一回はくるのがすごい！ 驚\\
早く春になってほしい！ 期待\\
バーベキューしたい。 期待\\
在庫が残り少なくなってる。 不安\\
ズボンが入りづらい。 不安\\
雪が降ると寒いね。 平静\\
おはよう。 平静\\
めっちゃねむい。 平静\\
\end{itembox}

  \subsection{実験結果}
精度検証実験の結果、システムの精度は 84.0\%であった。
本研究の顔文字出力システムを用いた出力結果を以下に示す。

\begin{itembox}[l]{出力された顔文字と感情の例}
  昨日のラーメンがおいしかった。 \verb|(*´∀｀*), 喜| \\
高級豆安く手に入って嬉しい！ \verb|( *´v`* ), 喜| \\
チャーシューが柔らかかった。\verb|(*´∀｀*), 喜|\\
この年になると二日酔いが辛い。\verb|(´・_・`), 不安|\\
この服はあまりかわいくない。\verb|('∀'), 悲|\\
カフェのランチじゃ物足りない。\verb|(・_・), 悲|\\
届いた靴が意外と大きかった…。\verb|('A`), 悲|\\
東京の物件どれも高い。\verb|( ・ω・), 悲|\\
高速バスは危ない！\verb|(T ^ T), 怒|\\
安い物件はよくないのばかり。\verb|(´・ω・`), 不安|\\
卒論がめんどくさい！\verb|( 'ω' ), 怒|\\
Amazon Prime Now で注文したら本当に1時間で届いた！ \verb|(*^o^*), 喜|\\
電車が5分に一回はくるのがすごい！\verb|(＠⌒ー⌒＠), 喜|\\
早く春になってほしい！ \verb|(o^∀^o), 期待|\\
バーベキューしたい。\verb|(つд⊂), 期待|\\
在庫が残り少なくなってる。 \verb|(@￣∀￣), 不安|\\
ズボンが入りづらい。\verb|(^_^;), 悲|\\
雪が降ると寒いね。\verb|(^_^), 平静|\\
おはよう。\verb|(*´∀｀), 平静|\\
めっちゃねむい。\verb|(´・皿・`), 平静|\\
\end{itembox}

また、各感情カテゴリの正解率を以下に示す。

\begin{table}
  \caption{各感情カテゴリの正解率}
  \centering
  \begin{tabular}{|c|c|} \hline
    感情カテゴリ & 正解率 \\ \hline \hline
    喜 & 96\% \\ \hline
    悲 & 92\% \\  \hline
    怒 & 68\% \\ \hline
    驚 & 64\% \\ \hline
    不安 & 80\% \\ \hline
    期待 & 92\% \\ \hline
    平静 & 96\% \\ \hline
  \end{tabular}
\end{table}

\section{考察}\label{sec:analyze}
\sref{sec:experiment}の精度検証実験の結果、本研究で構築した顔文字推薦システムの精度は 84\%であった。
本研究で確率付き感情語辞書の構築に使用した舟根の感情コーパスの精度は 98\%であった。
顔文字推薦システムの精度が既存研究より下がった原因として、3つ問題点が挙げられる。
以下に問題点を示す。

\subsection{問題点}
問題点の1つは、感情と顔文字が対応していないという問題である。
本研究では、確率付き感情語辞書を用いて文の感情を推定し、顔文字付き確率感情語辞書を用いて推定した感情に適切な顔文字を入力文に付与する。
しかし、顔文字付き確率辞書に登録された顔文字が、感情に適切ではないことが原因で、不適切な顔文字を入力文に付与してしまうことがある。
適切な顔文字の付与に失敗した例を以下に示す。

\begin{table}[htb]
  \centering
  \begin{tabular}{c||c|c} \hline
    入力文 & 推定された感情 & 推薦された顔文字 \\ \hline
    インターネットが繋がらない & 悲 & \verb|( ^ω^)| \\
    本当に腹がたつ & 怒 & \verb|(*´・ω・)|   \\
    明日が楽しみ & 期待 & \verb|(^o^;)| \\ \hline
  \end{tabular}
\end{table}

例えば、「インターネットが繋がらない」という文を形態素解析し、感情語辞書を参照すると、「繋がる」と「ない」の感情確率を取り出す。
これらの感情確率から最も値が大きいものを取り出すと、この文の感情は`悲'となる。
しかし、推薦された顔文字は「\verb|( ^ω^)|」であった。
この顔文字は、目のパーツから推測すると、`喜'の感情に分類されると考えられる。
このように、`悲'の感情属性の文に`喜'の顔文字を付与することは、顔文字推薦システムの精度が低まる要因となる。

この問題を解決するために、高島 \ibcite{takashima} の研究を参考に、顔文字解析を行う必要があると考えた。
高島は、Ptaszynski らによって構築された顔文字解析システム CAO (a system for emotiCon Analysis and decOding of affection information) \ibcite{cao}のアルゴリズムを参考にし、顔文字の感情推定を行った。
このシステムでは、顔文字の目や口のパーツに着目して感情推定を行い、「喜び」、「悲しみ」、「怒り」、「驚き」の4感情ごとに顔文字をデータベースに登録した。
本研究においても、CAO のアルゴリズムを参考にし、顔文字の目や口のパーツやその位置に着目し、顔文字それぞれの感情を推定する必要がある。
そして、ナイーブベイズ分類を用いて顔文字がある感情に属する確率を算出することで、感情に不適切な顔文字が推薦される問題は少なくなると考える。


問題点の2つめは、若者言葉が出現した際の感情抽出の失敗についてである。
現在、Twitter をはじめとする SNS では「やばい」や「ウケる」など、多くの若者言葉が用いられている。
しかし、感情語辞書の元となった感情コーパスは amazon の商品レビューを元に作られており、ここでは年齢層の違いから若者言葉が用いられていない。
そのため、感情を表す形態素が若者言葉であった場合に、若者言葉は未知語となり、文の感情を正しく推定できないという問題が発生する。
例えば、「窓からレインボーブリッジ見えてまじやばい！」という文がある。
これは、「窓からレインボーブリッジが見えることに感動している」という文である。
しかし、感情を表していると言える「やばい」という単語は感情語辞書に登録されていないため、この例文の感情は無感情となる。

この問題に対して、松本らの感情推定における若者言葉の影響 \ibcite{wakamono} の研究が行われた。
この研究では、Weblog から若者言葉を含む文を自動収集し、手動で若者感情コーパスを構築した。
そして、MeCab を用いて形態素解析し、感情語辞書を用いて抽出した単語に感情をタグ付けした。
このとき、文中に現れる顔文字も抽出し、顔文字辞書を用いて顔文字に感情をタグ付けした。
最後に、感情語と顔文字を SVM とナイーブベイズ分類を用いて学習させた。
本研究でも、この研究を参考にし、若者言葉を含む感情コーパスを構築する必要がある。

問題の3つめは、感情語辞書の偏りである。
全ての感情カテゴリの中で、`喜'と`平静'の正解率が最も高く、96\%であった。
しかし、`驚'の正解率は最も低く、64\%であった。
このように、正解率に大きく差が出た原因は、顔文字付き確率感情辞書の登録語数にあると考える。
顔文字付き感情語辞書の全登録語数は 69700語 である。
各カテゴリの登録語数を以下に示す。

\begin{table}[ht]
  \caption{各カテゴリの登録語数}
\centering
\begin{tabular}{c|c} \hline
  感情カテゴリ & 登録語数 \\ \hline \hline
  喜 & 26942 \\ \hline
  悲 & 11165 \\ \hline
  怒 & 6755 \\ \hline
  驚 & 3153 \\ \hline
  不安 & 3077 \\ \hline
  期待 & 5091 \\ \hline
  平静 & 13513 \\ \hline
\end{tabular}
\end{table}

このように、`喜'の登録語数と、`驚'の登録語数には大きく差がある。
各感情カテゴリの登録語数のばらつきを減らすことで、精度を高めることができると考えられる。

\section{まとめ}\label{sec:summary}
  %考察と原因の解明
本研究は、顔文字辞書と顔文字辞書を構築し、入力文の感情に見合った顔文字を推薦するシステムを提案すること目的とした。
\sref{sec:def}では、本研究で用いたナイーブベイズ分類について述べた。ナイーブベイズ分類は、過去の事例をもとに未知の文書があらかじめ与えられている場合にどのカテゴリに帰属するかを決定する分類手法である。
\sref{sec:theorem}では、ナイーブベイズ分類を用いて、Twitter から収集した文をもとにした感情語辞書と顔文字辞書の構築手法を述べた。このとき、学習データとして先行研究の感情コーパスを使用した。文中の形態素 $w_i$ が出現した際に、各感情 $e_2,e_2, \cdots ,e_7$ それぞれに帰属する確率を求めた。そして、これらの辞書を用いて入力文の感情を推定し、感情に適切な顔文字を推薦するシステムを提案した。このとき、出力された感情に最も適切な顔文字を選出するため、入力文の感情語と顔文字辞書に登録された感情の感情ベクトルのハミング距離を求め、ハミング距離が最も小さいものを入力文に付与した。
\sref{sec:experiment}では、顔文字推薦システムの精度を検証するため、5名の被験者に感情生起文を各感情につき5文ずつに入力してもらった。入力文に対して付与された顔文字が適切であれば正解、適切でなければ不正解とし、正解率を出した。この正解率を顔文字推薦システムの精度とした。この実験の結果、顔文字推薦システムの精度は 84.0\% であった。
\sref{sec:analyze}では、実験結果をもとに、顔文字推薦システムの問題点とその原因について述べた。適切な感情が抽出されていても顔文字が不適切であるという問題と、未知の若者言葉が感情語として文中に出現した場合に感情を推定できないという問題を明らかにした。今後はこれらの問題点を考慮し、さらなる精度向上を目指す必要がある。

 %参考文献ファイル設定
 \clearpage
 \bibliographystyle{ib_plain}
 \bibliography{lastthesisref} %bibファイルネーム
\end{document}
