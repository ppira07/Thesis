\documentclass[11pt,a4j]{jsarticle}

%本ファイル使用パッケージ
\usepackage[dvipdfmx]{graphicx}

%卒論スタイルファイル
\usepackage{sty/ib_thesis}

%TeX数式用
%\usepackage{amsmath}
\usepackage{ascmac}
%\usepackage{graphix}
\usepackage{url}
%argmax定義
\newcommand{\argmax}{\mathop{\rm arg~max}\limits}

%コメントアウト
\usepackage{comment}

%表紙パラメータ設定
%
\author{平野 万由子}     %本人名
\fyear{27}             %所属年度
\submit{28}{2}{29}    %提出和暦，月，日
\title{ナイーブベイズ分類を用いた文の感情推定と顔文字自動付与システムの提案} %論文タイトル

%ドキュメントスタート
\begin{document}
 \pagestyle{empty}
 \clearpage

 %表紙の生成
 \maketitle

 %日本語アブストラクト
 \jabstract{
近年、インターネットの普及により、多くのユーザが SNS (Social Networking Service)を利用している。
SNS では、テキストベースのやりとりが常套化しており、さらに簡潔な短文でやりとりをするチャット形式のコミュニケーションツールを利用するユーザが増加している。
しかし、テキストベースのやりとりでは、音声や表情といった非言語情報が欠落しがちである。
そのため、テキストの書き手と読み手の間に認識の齟齬が発生する。
そこで本研究では、テキストの感情を推定し、テキストの感情を補助するための顔文字を付与するシステムを提案する。
感情の推定では、感情語辞書を用いて品詞単位に感情を推定し、ナイーブベイズ分類器を用いて各感情のスコアを算出した。
また、算出した感情のスコアをもとに、顔文字辞書を用いて、推定した文の感情に適切な顔文字を付与する。
なお、本研究では、顔文字を`喜'、`悲'、`驚'、`不安'、`期待'、`怒'、`平静'の7感情に分類している。}

 %英語アブストラクト
 \eabstract{
Many users have been using SNS (Social Networking Service) recently.
On the SNS, an text-based exchange has been normally used. 
Furthermore, the number of users who are using communication tools for chatting has been increasing.
In the case that they write short sentences, the non-language information as sounds and expressions are lacked.
Therefore, the messages make the gap between the writers and the readers.
In this study, we propose that the system which extracts the emotion from the sentence, and give an emoticon to recievers.
To estimate emotion, we divide a sentence into some morphemes, then we calculate the score with a naive-Bayes classifier for each emotion.
We gives an emoticon which is suitable to the sentence with emoticon dictionary based on the calculated score.
In addition, we classified the emoticons under 7 emotions as `happiness', `sadness', `surprised', `anxiety', `expectation', `anger' and `sereneness'.
We decide the emotion of the tweet sentence.
Then, we automatically add an emoticon to the sentence.}

 %アブストラクトページの作成
 \makeabstract
 \newpage
 
 %目次の生成
 \tableofcontents
 \newpage
 
 %ここからページ数1
 \pagestyle{plain}
 \setcounter{page}{1}
 
 
 %本文
\section{はじめに}\label{sec:begin}
現在、SNS (Social Networking Service) の普及により多くのユーザーがSNSを利用している。
SNSとは、人と人とのコミュニケーションをインターネットを通してサポートするコミュニティ型の会員制 Web サービスのことである。

1990年後半、インターネットが普及し始めた。
この頃、遠隔でやりとりする手段はEメールが主体であった。
そして、その通信媒体は PC (Personal Computer) であり、各家庭において使われることが前提である。
1966年代には、文字の送信が安価に可能な移動体通信としてポケットベルが広まった。
これは、数字で文字を送る方法だった。
それから、PHS (Personal Handy phone System) が開発され、SMS (Short Message Service) が利用できるようになる。
しかし、PHS は基地局の設置が容易であるが、一つの基地局がカバーできる範囲が狭いため、郊外では利用しづらいというデメリットがあった。
携帯電話が開発された後、ユーザはCメールと呼ばれるショートメッセージでやりとりするようになる。
携帯電話は一つの基地局がカバーできる範囲が広いため、どこでも使えるというメリットがある。
その後に、携帯電話でもインターネットが利用できるようになり、移動体通信によるコミュニケーションには再びEメールが利用されるようになる。

2000年後半に入り、スマートフォンが普及した。
スマートフォンは、従来の携帯情報端末に携帯電話・通信機能を統合したものである。
従来の携帯電話には事前に豊富なアプリケーションが搭載されていたが、アプリケーションをユーザが追加することは困難であった。
しかし、スマートフォンには汎用OSが搭載されており、ユーザが自由にアプリケーションを追加することができる。
このように、スマートフォンにはPC の環境とあまり差異なく使えるという特徴がある。
そのため、従来の携帯電話に合わせて、PC のような多彩な機能を備えていることに注目が集まった。

そこでスマートフォンの普及に合わせて、SNSの利用者数が増加した。
これは、SNSを運営する各社がSNSの利用に特化したスマートフォン用のアプリケーションを次々と開発し、スマートフォン利用者が手軽にSNSを利用できるようになったことが要因であると言える。

SNSで使われるチャットツールの代表例として、LINE\raisebox{.5zw}{\scalebox{.5}{\textregistered}} や、Twitter\raisebox{.5zw}{\scalebox{.5}{\textregistered}} がある。
これらのサービスには、ユーザが短文でやりとりするという特徴がある。
また、短文でやりとりが行われるため、文の感情を強調・補助するために顔文字が使われるという特徴がある。
従って、このようなコミュニケーションにおいて顔文字は、コミュニケーションの円滑化に役立ち、また必須と言える。

しかし、顔文字を入力するには、入力変換機能を用いて逐一顔文字で表したい単語を入力し、変換する必要がある。 
この入力変換機能に登録されている顔文字の種類は少ない。
しかし、web 上の顔文字辞書は種類が豊富であるが、web上からコピーをして入力フォームに貼り付けをするのは非効率的と言える。
つまり、web 上の顔文字辞書から入力文に適切な顔文字をただ一つ選ぶには時間がかかるという問題点がある。
これは即応性が求められるチャットにそぐわない。

そこで、本研究は入力文の感情を推定して顔文字を付与することを目的とする。
多種多様な顔文字を自動で付与できれば、このような短文でやりとりされる即応性が必要なコミュニケーションを補助することができる。
本研究では入力文の感情を、`喜'、`悲'、`怒'、`驚'、`不安'、`期待'、`平静'の7感情に分類する。
そしてその感情に適切な顔文字を入力文に付与する。
これにより、ユーザは自由に文を入力し、その文に対して多彩な顔文字が自動で付与されることが期待できる。

本論文の構成は以下の通りである。
\sref{sec:begin} では、本研究の背景及び目的を記述した。
\sref{sec:relatedworks} では、本研究を行うにあたって参考にした文献・研究を説明する。
\sref{sec:def} では、本研究で用いるベイズ推定について記述する。
\sref{sec:tools}では、本研究で用いる自然言語処理の基礎技術について記述する。
\sref{sec:system}では、本研究で構築した顔文字自動付与システムの構築手順と方法を記述する。
\sref{sec:experiment}では、精度検証実験の手順とその結果を記述する。
\sref{sec:summary}では、本論文のまとめを記述する。

\section{先行研究}\label{sec:relatedworks}
感情推定とは、テキストの書き手の感情を判別する研究である。
これまで、感情推定に関する研究は、主に認知科学や心理学の分野で行われた。
しかし、近年では自然言語処理の分野で活発に研究が行われている。
例えば、「テストでいい点数が取れてとても嬉しい。」というテキストがある場合、この書き手の感情は`嬉しい'という単語から`喜'であると判断できる。
このような人間が発話に用いる自然言語を、計算機で機械的に処理することを自然言語処理と呼ぶ。

まず菅原らは、感情語辞書を用いて文からの感情抽出を行った\ibcite{suga}。
感情語辞書とは、形容詞や動詞などの一般品詞に、それらがどの程度各感情に属するかを付与した辞書である。
菅原らの感情語辞書の作成では、人手で構築した感情語辞書を用いている。
そして、シソーラス\footnote{単語の上位下位概念をまとめた辞書}を用いて入力文の単語と感情語辞書の単語の類似度を計算している。

また、コーパスを用いて感情を推定する手法もある。
松本らは、感情コーパスを用いて文単位に感情を抽出した\ibcite{matsumoto}。
感情コーパスとは、文が表す感情を判定し、その感情を文に付与したものの集まりである。
松本らは、この感情コーパスの作成に、人手で感情をタグ付けする方法を用いた。

そして、舟根はナイーブベイズを使用して感情推定し、半自動的に感情コーパスを作成した\ibcite{funane}。
この研究では、まず入力文の形態素ごとにコーパスを参照し、その形態素がコーパスに含まれる数を感情属性ごとに付与する。
次に、ナイーブベイズ分類を使用して感情を推定する。
そして、uni-gram, bi-gram, tri-gram \footnote{連続した要素n個のかたまりのこと。bi-gramの場合は、連続した2つの形態素を1つのかたまりとして扱うことを意味する。} の三つの分割方法においての出力感情が全て一致したとき、その文とその感情を感情コーパスに追加した。
これらを用いた文の感情推定精度は71.2\%であった。

山本らは、感情コーパス構築のための文中の語に基づく感情分類手法を提案した\ibcite{yamamoto}。
この研究では、感情コーパスを学習データとして Support Vector Machine (SVM) やナイーブベイズ分類を用いて文の感情値を出力している。
この感情値を用いて、文に感情タグを付与し、半自動的に感情コーパス作成した。
この感情値は、形態素ごとの感情コーパスの文に現れる頻度をもとに算出している。

また、顔文字からの感情抽出や、文への顔文字推薦システムを提案する研究がされている。
まず篠山らは、顔文字を考慮した対話テキストの感情推定に関する研究を行った\ibcite{shinoyama}。
この研究では、顔文字を考慮した感情推定システムを提案している。
この感情推定システムでは、文章と顔文字それぞれの感情を推定し、両方の結果をもとに全体の感情を推定している。
しかし、この研究では、対象とする顔文字が固定されているため、幅広い顔文字推薦への応用は難しい。

そこで、より大きい規模のものとして、Ptaszynski らの CAO システム \ibcite{cao}があげられる。
このシステムには顔文字データベースがあり、そこには1万個以上の顔文字がパーツごとに登録されている。
この顔文字データベースを用いて、入力文の顔文字とのマッチングを行う。
そして、入力文の顔文字と顔文字データベース内の感情タグを照らし合わせ、感情スコアの統計を算出する。
これにより、顔文字の感情解析が可能としている。
例えばこのシステムにより、\verb|「(＾Ｏ＾)」|という顔文字は、顔文字データベースを参照し、`喜'という数値が最も高いと判定されたとする。
しかし、このシステムでは例のように顔文字の感情を推定することができても、文の感情を推定することができない。
さらに、顔文字データベースは人手で構築する必要があり、そのままの利用は困難である。

また、顔文字解析に関連して、橋本の Twitter の文に絵文字を推薦する研究がある\ibcite{hashimoto}。
この研究では、まず Twitter の文を形態素解析し、それを単語単位で tri-gram に分割する。
そして、絵文字入りコーパスを用い、その単語 tri-gram と類似する文をコーパス中から探し、その文で用いられている絵文字を挿入している。
ただこのとき、ポジネガ判定を行ったうえで感情推定を行うという 2 段階推定にすることにより、付与される絵文字の精度が向上することが徳久らの研究から明らかになっている\ibcite{tokuhisa}。
ポジネガ判定とは、感情を「ポジティブ」、「ネガティブ」、「ニュートラル」の3極性で判定することである。
そのため徳久らは、感情が起因する要因となる事態を表す文を、感情生起要因コーパスを用いてポジネガ判定し、感情推定を行った。

以上により、感情推定には感情語辞書や感情コーパスを用いる手法が多いことがわかる。
そして、これらを構築する手段にはナイーブベイズや SVM がよく用いられることがわかる。
また、顔文字からの感情抽出には、CAO システムのような顔文字の感情解析を用いる手法があることがわかった。

\section{感情推定における自然言語処理の基礎技術}\label{sec:tools}
\subsection{Twitter API}
API とは、Application Programming Interface のことであり、あるソフトウェアやサービスの機能やデータなどを、外部のプログラムから呼び出して利用するための手順やデータ形式のことである。

Twitter API は、Twitter 社が提供している API である。
これによって、ユーザが Tweet 文をソフトフェアで利用することができる。
このTwitter API は以下のような機能を持っている。

\begin{itemize}
  \item Tweet の投稿
  \item Tweet の検索
  \item タイムライン の取得
  \item リストの取得
\end{itemize}
これらの機能により、ウェブサイトやアプリなどから Twitter の機能の呼び出しや検索などを、サービスサイトではなくソフトウェア上から扱うことができる。
ただし、このTwitter API を利用する場合、次のことに注意しなければならない。
それは、Twitter API には、REST API と Streaming API の二種類があるということである。

REST API は、公開された Tweet を取得するたびにHTTP 接続を行う。
そして、蓄積された過去の Tweet 情報や Tweet の投稿、ユーザ情報の変更などを行うことができる。
このREST API では、 URL に要求などを定められた形式で文字列にしたクエリを渡し、そのレスポンスを取得する REST (Representational State Transfer) を利用している。
このREST API は細かい機能を持っているため、通常の Twitter クライアントや BOT で利用される。
ただし REST API はサーバ負荷が高いため利用規制があり、一定時間ごとにAPI を呼び出せる回数が制限されている。
そのため、制限数を使い切ってしまった場合、API の呼び出しが一定時間できなくなる。
API 1.1 では15分間にその API を使ったアプリごとにそれぞれ呼び出しの制限回数が定められていた。
従って大量の文を取得することには向いていないと言える。

一方で、Streaming API は一度接続すると HTTP 接続を保ったまま、接続が切断されるまで Tweet 情報を取得し続けることができる API である。
そのため、タイムラインの変更をリアルタイムにそして大量に受け取ることができる。
仕組みとしては、REST API と同じく REST でアクセスを行う。
しかし、タイムラインの更新が発生するまでレスポンスを保留させるとこで、高いリアルタイム性を実現している。
ただし、一度に何本も API を接続することができない点や、切断と接続を短時間に連続で行うことができない点、また過去の Tweet 文を取得できない点などの制約がある。
しかし、REST API とは違い、API の利用回数規制がかからないという利点がある。
よって上記のようにStreaming API は、データ解析などで大量の Tweet 文を必要とする開発者向けの API である。

本研究では、まず顔文字の取得と、その顔文字が表す感情を推定するためにナイーブベイズを使用した。
この場合、ベイズ推定の推定確率の確からしさを大きくするために、その確率を計算するためのベースとなるコーパスの量が重要となる。
このとき必要となるコーパスはすなわち、1) 文章より感情推定が容易なテキスト、 2) 顔文字が使用されているテキスト、これら二つの条件を充すような大量のテキストである。
このような大量のテキストを取得するためには Twitter の Tweet 文が適切であると考えた。
従って本研究では Streeming API を使用し、リアルタイムに Tweet 文の取得を行った。
そこで取得されたTweet 文の例を以下に示す。

\begin{itembox}[c]{Tweet 文の例}
  こんなに素敵なものを受け取っていいのか\verb|(T_T)|ほんとにありがとう！\\
  おやすみなさい\verb|(´ω`)| \\
  スーパーワーカーってゆう響きが素敵です\verb|( ´ ▽ ` )| \\
  明日朝早いねん\verb|(^_^;)| \\
  あっ、なんかTwitterとかFBで見ました(笑)\\
  やっぱ羨ましくない！拗ねてる\verb|(｀へ′)| \\
  痛いしむかつくんだけど\verb|(*_*)| \\
  楽しみです\verb|(*^^*)| \\
  がんばれ〜っ！\verb|ヽ( ´ー｀)ノ|\\
\end{itembox}

このように顔文字が入った Tweet 文を大量に取得することが分かる。

\subsection{MeCab と Natto}
まず、形態素解析 (Morphological Analysis) とは、文章を自動で分かち書きする自然言語処理の手法の一つである。
簡単には、ある文章やフレーズを、意味を持つ最小限の単位である「形態素」に分解し、辞書を利用して形態素の品詞や活用などの情報を付け加えることである。
例えば、「私は家で勉強します」という日本語の文は、形態素解析を用いると「私/は/家/で/勉強/し/ます」という形態素から成り立っていることが分かる。
このような形態素解析は現在、かな漢字変換や機械翻訳、音声認識で使用されている。

MeCab \ibcite{mecab} は、奈良先端科学技術大学院大学が開発したオープンソースの形態素解析エンジンである。
MeCab は単体では機能せず、形態素ごとに分割するためには品詞や意味が内蔵された辞書が必要になる。
MeCab 用の基本的な辞書として IPA 辞書\ibcite{ipa}や JUMAN 辞書\ibcite{juman}、UniDic 辞書\ibcite{unidic}がある。
これらの基本的な辞書を使ってもよいが、自分で任意の単語を手動で辞書に追加することも可能である。
このMeCabには、標準で IPA 辞書が搭載されている。
そこで初期状態のMeCab を用いて例文「私は家で勉強します」を形態素解析すると、以下のような結果が得られる。

\begin{itembox}[l]{形態素解析結果の例}
私  名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\\
は  助詞,係助詞,*,*,*,*,は,ハ,ワ\\
家  名詞,一般,*,*,*,*,家,イエ,イエ\\
で  助詞,格助詞,一般,*,*,*,で,デ,デ\\
勉強  名詞,サ変接続,*,*,*,*,勉強,ベンキョウ,ベンキョー\\
し  動詞,自立,*,*,サ変・スル,連用形,する,シ,シ\\
ます  助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\\
EOS
\end{itembox}

上に示したように、MeCab からは、その要素ごとにカンマで区切られた CSV (Commma Separated Value) 形式で出力される。
MeCab の出力フォーマットは、左から、「表層形」、「品詞」、「品詞細分類1」、「品詞細分類2」、「品詞細分類3」、「活用形」、「活用型」、「原形」、「読み」、「発音」となっている。
「表層形」とは、文中に現れる単語そのもののことである。
「品詞」とは、単語を形態と職能によって分類した種別である。
「品詞細分類1」、「品詞細分類2」、「品詞細分類3」とは、品詞をさらに細かく分類したものである。
また「活用形」とは、品詞の活用した語形である。
「活用型」とは、品詞の活用の型で、
そして「原型」とは、単語の原型のことである。これは例えば、表層型が「楽しかっ」である場合、原型は「楽しい」となる。
なお「読み」、「発音」は、単語の読み方と、その発音をカタカナで表している。

この MeCab をプログラミング言語 Ruby から利用するためのGem パッケージとして、「Natto」がある。
Gem パッケージとは、プログラミング言語 Ruby で使用されるライブラリやアプリケーションをパッケージで配布するものである。
Natto はその Gem パッケージの一つであり、MeCab を利用しやすくするものである。

本研究では、この Natto を用いてTwitter から集めた大量のデータを自動的に形態素解析した。
例えば、「今日は学校を休みたい」という Tweet 文は 以下のようなプログラムで形態素解析できる。

\begin{itembox}[l]{プログラムの例}
\begin{verbatim}
require 'natto'

text = '今日は学校を休みたい'

nm = Natto::MeCab.new
nm.parse(text) do |n|
  puts "#{n.surface} #{n.feature}"
end
\end{verbatim}
\end{itembox}

上記のプログラムを実行すると、以下のように表示される。

\begin{itembox}[l]{プログラムの実行結果}
  今日  名詞,副詞可能,*,*,*,*,今日,キョウ,キョー \\
  は  助詞,係助詞,*,*,*,*,は,ハ,ワ\\ 
  学校  名詞,一般,*,*,*,*,学校,ガッコウ,ガッコー\\
  を  助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\\
  休み  動詞,自立,*,*,五段・マ行,連用形,休む,ヤスミ,ヤスミ\\
  たい  助動詞,*,*,*,特殊・タイ,基本形,たい,タイ,タイ\\
 BOS/EOS,*,*,*,*,*,*,*,*\\
\end{itembox}

この Natto を用いることで、自動的に大量の Tweet 文を処理することができる。
また、プログラムから制約付きの形態素解析をすることができる。
例えば、形態素の境界の制約をつけたり、特定の形態素ごとに品詞分類を限定したりできる。
つまり、Natto を用いることで、効率的に目的に沿った形態素解析ができると言える。

\section{ベイズ推定と感情推定}\label{sec:def}
本研究では、文の感情感情推定についてベイズ推定を用いている。
そこで、\ssref{sec:defbayes}では、ベイズ推定とベイズの定理を説明する。
\ssref{sec:defnaivebayes}では、本研究で用いたナイーブベイズ分類について説明する。

  \subsection{ベイズ推定とは}\label{sec:defbayes}
ベイズ推定とは、ベイズの定理に基づき、観測事象からその原因となる事象を確率的に推論する手法である。
このベイズ推定の基礎となるベイズの定理は、18世紀にイギリスの牧師であるトーマス・ベイズが提案した。
このベイズの定理は統計学に応用され、ベイズ統計学の代表的な手法となっている。
ベイズの定理は、条件付き確率に準拠している。

まず条件付き確率とは、「事象$A$が起こったという条件下で事象$B$が起こる確率」であり、$P(B|A)$と表される。この$P(B|A)$は以下のように計算できる。

まず$B$が発生する確率$P(B)$は、すべての事象$U$のうち$B$が発生する確率である。関数$n$を引数の出現回数を返す関数としたとき、$P(B)$は次のように書ける。

\begin{equation}
  P(B)=\frac{n(B)}{n(U)}
\label{pb}
\end{equation}

また、$A$と$B$が同時に発生する確率$P(A \cap B)$は、すべての事象$U$のうち$A$と$B$が同時に発生する確率であり、次のように求められる。

\begin{equation}
P(A \cap B)=\frac{n(A \cap B)}{n(U)}
\label{pab}
\end{equation}

そして$P(B|A)$は，事象$A$が発生したという条件下で事象$B$が発生する確率であるので、事象$B$が発生した中、事象$A$が発生する確率である。すなわち、事象$B$の中で、事象$A$と$B$が同時に起こる確率である。
よって、$P(B|A)$ は次のように求めることができる。

\begin{equation}
  P(B|A)=\frac{n(A \cap B)}{n(A)}
\label{pba}
\end{equation}

これらから、式(\ref{pb})、(\ref{pab})を式(\ref{pba})に代入すると、以下のようになる．

\begin{eqnarray*}
  P(B|A) & = & \frac{n(A \cap B)}{n(A)}\\
         & = & \frac{n(U)}{n(B)} \cdot \frac{n(A \cap B)}{n(U)} \\
         & = & \frac{1}{P(B)} \cdot P(A \cap B) \\
         & = & \frac{P(A \cap B)}{P(B)}
\end{eqnarray*}

以上より、条件付き確率は次のように定義できる。
\[
  P(A|B)=\frac{P(A \cap B)}{P(B)}
\]

次にベイズの定理である。
そのベイズの定理は、以下の式で表される。

\[
P(B|A)=\frac{P(A|B)P(B)}{P(A)}
\]

\begin{comment}
このとき、事象$B$が発生する確率である$P(B)$は事前確率と呼ばれる。
$P(B|A)$は事象$A$が発生したあとに事象$B$が発生する条件付き確率を表す。これを$B$の事後確率と呼ぶ。
また、$P(A|B)$は事象$B$が発生したあとの事象$A$が発生する条件付き確率を表す。これを尤度と呼ぶ。
これは$B$が真の際にデータが得られる尤度を表し、尤度関数と呼ばれる。
この式から、事後確率$P(B|A)$は事前確率$P(B)$と尤度$P(A|B)$の積に比例することが分かる。
\end{comment}

このベイズの定理は以下のように構成される。

まず、$A$に対する$B$の条件付き確率は次のように表された。

\begin{equation}
P(B|A)=\frac{P(A \cap B)}{P(A)}
\label{shiki1}
\end{equation}

よって、$B$に対する$A$の条件確率は次のようになる。

\begin{equation}
P(A|B)=\frac{P(B \cap A)}{P(B)}
\label{shiki2}
\end{equation}

式(\ref{shiki1})、(\ref{shiki2})にそれぞれの右辺の分母を両辺にかけると、以下のようになる。

\begin{eqnarray}
  P(A)P(B|A)=P(A \cap B) \label{shiki3}\\
  P(B)P(A|B)=P(B \cap A) \label{shiki4}
\end{eqnarray}


$P(A \cap B)=P(B \cap A)$だから、式(\ref{shiki3})、(\ref{shiki4})より、次が成り立つ。

\begin{eqnarray}
  P(A)P(B|A)=P(B)P(A|B)
\end{eqnarray}

従って、この両辺を$P(A)$で割ると、以下のベイズの定理が導出される。

\begin{eqnarray}
  P(B|A)=\frac{P(B)P(A|B)}{P(A)}
\end{eqnarray}

なおベイズの定理において、$P(B|A)$を事後確率\footnote{$A$が起きた後に$B$が起きる確率。}、$P(B)$を事前確率\footnote{$A$が起きる前の$B$が起きる確率。}、また$P(A|B)$を尤度\footnote{もっともらしさを保証する確率。}と言う。

この式を素直に用いたベイズ推定では膨大な反復計算が必要となる。
それは、観測事象が増えると確率$P(A)$と$P(A|B)$を更新しなければならないからである。
しかし現在では、コンピュータの処理性能が向上したことにより、心理学や経済学、そしてインターネットの検索やメールフィルタと、幅広く応用されるようになった。

このようにベイズ定理では、ある事象$B$が発生したときに、その原因事象が事象$A$であった確率を観測された事象から求めることができる。
これにより、例えばある文はどのような感情を持つかというサンプルを大量に与えることで、任意の入力文に対してその文を作った感情が何であったのかを推定できる。
なお、ベイズ推定にはモデルが複雑である場合にも推定が可能であるというメリットもある。

 \subsection{ナイーブベイズ分類}\label{sec:defnaivebayes}
ナイーブベイズ分類は、ベイズ推定を用いた分類手法の一つである。
ナイーブベイズ分類では、特徴ベクトル間に独立性を仮定したベイズの定理に基づいて分類している。
これは簡単には、分類対象の要素間には共起関係がないと仮定して分類することを意味する。

このナイーブベイズ分類では、特徴間の独立性を仮定しているので、計算が簡素化されている。
つまり、ある文書をカテゴライズする場合は、単語間の相関関係を考慮せずに、その要素である単語の出現確率のみを学習させればよいことになる。
そのため、実装が容易で、さらに学習時間も短い。
また、有効な特徴を用いることができれば、高い分類精度が得られることも分かっている。

次に、ナイーブベイズ分類の数式について説明する。
ナイーブベイズは、ベイズの定理の数式を用いて分類を行うものである。
そのベイズの定理は以下であった。

\begin{equation}
  P(B|A)=\frac{P(A|B)P(B)}{P(A)}
  \label{eq:nb}
\end{equation}

そこである対象$A$をあるカテゴリ$B_i$へ分類することを考える。これは言い換えると、対象となる$A$は、そもそもカテゴリ$B_i$にどれくらい属したものかを推測することとなる。

そこでいま$A$はいくつかの要素$w_1, w_2, \ldots, w_n$から成り立っているとする。
従って、$A$は次のような対として表すことができる。

\begin{equation}
  A = (w_1, w_2, \cdots ,w_n)
\end{equation}

そして対象$A$がカテゴリ$B_i$である確率は、ベイズの定理を用いて次のようにできる。

\begin{eqnarray}
  P(B_i|A) & = & \frac{P(A|B_i)P(B_i)}{P(A)} \\
  P(B_i|w_1, w_2, \cdots ,w_i) & = & \frac{P(w_1, w_2, \cdots ,w_i|B_i)P(B_i)}{P(w_1, w_2, \cdots ,w_i)}
\end{eqnarray}

このとき右辺の$P(w_1, w_2, \cdots ,w_i|B)$は独立仮定により、任意の$w_i$と$w_j$ ($i \not = j$) の間に確率上の関係がないとされる。
従って、$P(B_i|w_1, w_2, \cdots ,w_i)$は次のように計算される。

\begin{eqnarray}
  P(B_i|w_1, w_2, \cdots ,w_n) & = & \frac{P(w_1, w_2, \cdots ,w_n|B_i)P(B_i)}{P(w_1, w_2, \cdots ,w_n)}\\
  & = & \frac{(P(w_1|B_i) \cdot P(w_2|B_i) \cdots P(w_n|B_i)) \cdot P(B_i)}{P(w_1, w_2, \cdots ,w_i)}\\
  & = & \frac{1}{P(w_1, w_2, \cdots ,w_n)} \cdot \prod_{j}^{n}(P(w_j|B_i)P(B_i)) \\
  & = & \frac{P(B_i)}{P(w_1, w_2, \cdots ,w_n)} \cdot \prod_{j}^{n} P(w_j|B_i)
\end{eqnarray}

またナイーブベイズ分類では、この対象$A$が複数あるカテゴリ$B_1, \ldots ,B_m$ のどれかに属するのかを、その確率値を用いて比較して判断することになる。つまりこれは以下の式を比較することを意味する。

\[
P(B_i|w_1, w_2, \cdots ,w_n) = \frac{P(w_1, w_2, \cdots ,w_n|B_i)P(B_i)}{P(w_1, w_2, \cdots ,w_n)}
\]
と
\[
P(B_j|w_1, w_2, \cdots ,w_n) = \frac{P(w_1, w_2, \cdots ,w_n|B_i)P(B_j)}{P(w_1, w_2, \cdots ,w_n)}\\
\]

このとき、分母の$P(w_1, w_2, \cdots ,w_n)$が計算される全てのカテゴリに対して同じであるため、この分母$P((w_1, w_2, \cdots ,w_n)$は考慮する必要がなくなる。そのため、上記式は次のように簡略化することができる。

\begin{equation}
  P(B_i|A)\propto P(A|B_i)P(B_i) = \frac{P(B_i)}{P(w_1, w_2, \cdots ,w_n)} \cdot \prod_{j}^{n} P(w_j|B_i)
\end{equation}

よって独立仮定をおいたナイーブベイズ分類は上記式により分類ができる。
なお、記号 $\propto$ は、右辺が左辺に比例することを表す。


\section{顔文字自動付与システム}\label{sec:system}
まず、顔文字自動付与システムの手順を\fref{fig:system}に示す。

\begin{figure}[h]
  \includegraphics[scale=0.4]{./system.png}
  \caption{顔文字自動付与システムの手順}
  \label{fig:system}
\end{figure}

本研究の顔文字自動付与システムでは、「感情語辞書」と「顔文字辞書」を用いて入力文の感情を推定し、自動で顔文字を付与する。
ここで用いる辞書は、確率付き感情語辞書と確率付き顔文字辞書である。
確率付き感情語辞書には、形態素、形態素の感情属性、形態素が感情に属する確率値 (感情属性値) が登録されている。本研究では、この辞書を舟根の研究で構築された感情コーパスをもとに構築した。
また、確率付き顔文字辞書には、顔文字、顔文字の感情属性、絵文字が感情に属する確率値 (顔文字確率値) が登録されている。
これは、Twitter から収集した Tweet 文の顔文字を使用して、構築した。
その際の分類手法にはナイーブベイズ分類を用いている。

本システムは、これら辞書を用いて入力文の感情を推定し、顔文字を自動で付与する。
よって本章では、用いるナイーブベイズ分類の具体的な説明と、これらの辞書の構築の手順、そして顔文字自動付与システムの構築手順を述べる。

  \subsection{感情推定で用いるナイーブベイズ分類}\label{sec:thesisnaivebayes}
本研究では、感情属性値を算出するためにナイーブベイズ分類を用いる。
このとき各形態素の感情属性値は、舟根の研究で構築された感情コーパスをもとに算出する。
それを用いて確率付き感情語辞書と確率付き顔文字辞書を構築する。
また確率付き顔文字辞書は、Twitter から収集した 12 万件の tweet をもとに構築する。
まずその過程で使われるナイーブベイズ分類について説明する。

コーパス中の1文を文$s$とする。このとき文$s$はいくつかの形態素$w_1,w_2, \cdots ,w_j$で構成されている。
そして分類する各感情カテゴリは、`喜'、`悲'、`怒'、`驚'、`不安'、`期待'、`平静'の7感情であったので、それを $c_1,c_2, \cdots , c_i, \cdots , c_7$と表す。これらから、$s$が分類されるべき感情属性はナイーブベイズ分類より、$P(c_i|s)$を最大化するような感情 $\hat{c}$ であるとできる。
これは以下のように算出される。

まず文$s$における感情$c_i$の確率はナイーブベイズより次のようにできる。

\[
  P(c_i|s)=P(c_i)P(s|c_i)
\]

このとき、$P(c_i|s)$を最大にする $\hat{c}$は次のようにできる。

\begin{eqnarray*}
C & = & \{c_1,c_2 \cdots ,c_7\}\\
  \hat{c} & = & \argmax_{c_i \in C} P(c_i|s) \\
          & = & \argmax_{c_i \in C} P(c_i|w_1,w_2,\cdots ,w_n) \\
          & = & \argmax_{c_i \in C} P(c_i)P(w_1,w_2,\cdots ,w_n|c_i) \\
\end{eqnarray*}

これは、ナイーブベイズの独立性仮定により次のようになる。

\[
  \hat{c}=\argmax_{c_i \in C} P(c_i)\prod_{k=1}^n P(w_k|c_i)
\]

この $\hat{c}$が、$s$が分類される感情属性である。

そして$P(w_k|c_i)$は以下のように表すことができる。

\[
P(w_k|c_i)=\frac{感情 c_i とタグ付けされた全ての文で形態素 w_k が出現する回数}{感情 c_i とタグ付けされた全ての文の形態素の数}
\]

これにより、文中の形態素 $w_k$が出現した際に、感情属性$c_1,c_2, \cdots ,c_7$にそれぞれどのくらい帰属するかを求める。
この$P(w_k|c_i)$は舟根の感情コーパスにより算出される。
なおこのような、ある形態素がそれぞれの感情にどれだけ帰属するかという確率を、「感情属性値」と呼ぶ。

以上の手法を基本的には用いるが、このナイーブベイズ分類を使用するときはゼロ頻度問題に注意しなければならない。
それは文$s$において、辞書に存在しない形態素$w_\mathit{new}$が出現した場合、$w_\mathit{new}$ の確率 $P(w_\mathit{new}|c)$ は0と推定されることであった。

ナイーブベイズでは各形態素の確率の積で文の感情推定が行われているため、
文中のどれか1つの形態素が感情語辞書に登録されていないとき、その文$s$の感情$c$の確率は0となってしまう。
つまり、$w_\mathit{new}$以外の任意の形態素$w_i$で有用な確率値が算出されても、積を求めるため$w_\mathit{new}$により結果が0となり、有用な形態素が無視されることになる。
この問題を、ゼロ頻度問題と呼ぶ。

この問題を避けるため$W_\mathit{new}$の出現確率を求める場合、出現回数を補正した値を用いるスムージングが行われる~\ibcite{textmining}。
そのスムージングは以下のように行われる。

\[
  P(W_\mathit{new}|C)=\frac{単語 W_\mathit{new} の数 + \alpha }{カテゴリC の語彙数 + \alpha }(\alpha は任意の数)
\]

このように、一定の数を予め加えておくことで、未知の単語$W_\mathit{new}$が出現した場合に確率を0にしない。これにより、その他の要素の結果を考慮できるようになる。

本研究では、単純な加算法であるラプラス法を用いてスムージングを行う。
これはラプラススムージングと呼ばれる。
ラプラススムージングでは、出現頻度を求める際に全ての出現回数に $\alpha=1$ を加える。
 

  \subsection{コーパスを用いた確率付き感情語辞書の構築}\label{sec:tweetcorpus}
まず、確率付き感情語辞書の構築手順を\fref{fig:kanjogo}に示す。

\begin{figure}[h]
  \includegraphics[scale=0.4]{kanjogo.png}
  \caption{確率付き感情語辞書の構築手順}
  \label{fig:kanjogo}
\end{figure}

確率付き感情語辞書には、形態素、形態素の感情属性、形態素が感情に属する確率値 (感情確率値) が登録されている。
この確率付き感情語辞書は、舟根の感情コーパスをもとに構築している。
これは、文に含まれる形態素を uni-gram、bi-gram、tri-gram に分割し、それぞれ感情が一致したものを感情コーパスに登録している。

いま感情コーパスが以下のものであるとする。

\begin{table}[htb]
  \caption{感情コーパスの例}
  \centering
  \begin{tabular}{c|c} \hline
    文 & 感情属性 \\ \hline \hline
    とても楽しい1日だった。 & 喜 \\
    指輪をなくしてしまった & 悲 \\
    この会社、むかつきます。 & 怒 \\ 
    安さに衝撃を受けました。 & 驚 \\
    ちゃんと届くか心配です。 & 不安 \\
    家に届くのが楽しみです。 & 期待 \\
    夫へのプレゼントに購入。& 平静 \\ \hline
  \end{tabular}
\end{table}

このように、感情コーパスには文とその感情属性が一行ずつ登録されている。
またこのとき、文と感情属性は半角スペースで区切られている。

まず、感情コーパスを文と感情属性に分け、文のみを MeCab を用いて形態素解析した。
形態素解析の例を以下に示す。

\begin{table}[htb]
  \caption{感情コーパスの形態素解析結果}
  \centering
  \begin{tabular}{c} \hline
    文\\ \hline \hline
    とても/楽し/い/1/日/だっ/た/。\\
    指輪/を/なくし/て/しまっ/た/。\\
    この/会社/、/むかつき/ます/。 \\ 
    安/さ/に/衝撃/を/受け/まし/た/。\\
    ちゃんと/届く/か/心配/です/。\\
    家/に/届く/の/が/楽しみ/です/。\\
    夫/へ/の/プレゼント/に/購入/。\\ \hline
  \end{tabular}
\end{table}


次に、各形態素の感情属性値を算出する。
なおこのとき感情語として、「動詞」、「名詞」、「形容詞」、「感動詞」の基本形のみを用いた。

例えば、感情コーパスにある「とても楽しい1日だった。 喜」は、形態素解析すると次のようになる。

  \begin{itembox}{形態素解析結果}
    とても	副詞,助詞類接続,*,*,*,*,とても,トテモ,トテモ,,\\
    楽しい	形容詞,自立,*,*,形容詞・イ段,基本形,楽しい,タノシイ,タノシイ,たのしい/愉しい/楽い/楽しい,\\
    １	名詞,数,*,*,*,*,１,イチ,イチ,,\\
    日	名詞,接尾,助数詞,*,*,*,日,ニチ,ニチ,,\\
    だっ	助動詞,*,*,*,特殊・ダ,連用タ接続,だ,ダッ,ダッ,,\\
    た	助動詞,*,*,*,特殊・タ,基本形,た,タ,タ,,\\
    。	記号,句点,*,*,*,*,。,。,。,,\\
    EOS
  \end{itembox}

ここで使用するのは、「動詞」、「名詞」、「形容詞」、「感動詞」である形態素の標準形であるので、結果以下のものが使用される。

\begin{itembox}{使用される形態素}
   楽しい \\
   １\\
   日
 \end{itembox}
 
 次に形態素の感情属性の確率値を求める。この確率を感情属性値と呼ぶ。
 感情属性 $e_i$ に感情語 $w_j$ が出現する感情属性値 $P(w_j|e_i)$ は以下の式で求められる。

 \[
 P(w_j|e_i)=\frac{感情 e_i とタグ付けされた全ての文で形態素 w_j が出現する回数 +1}{感情 e_i とタグ付けされた全ての文の形態素の数 + コーパスに含まれる形態素数}
 \]

 いま$e_i$を「喜」とすると、使用している感情コーパスで「喜」のタグがついた文は「とても楽しい1日だった。 喜」である。これを形態素解析すると、「とても/楽し/い/1/日/だっ/た/。」となり、その形態素数は8個である。よって、
 \[
 P(楽しい|喜)=\frac{1 + 1}{8+1} = 0.222\cdots
 \]
 となる。

 よって、確率付き感情語辞書には次のようなものが記録される。
 \begin{itembox}{記録されるデータ}
   喜,楽しい,0.22222222222222 \\
 \end{itembox}

 これらを感情コーパスに含まれる全ての形態素について行い、感情語辞書を作成する。
 

実際に構築した確率付き感情語辞書の一部を以下に示す。

\begin{itembox}[h]{構築した感情語辞書}
   喜,気に入る,0.0045297095656807885\\
   悲,悔しい,0.002236541049798115\\
   怒,酷,0.000362844702467344\\
   驚,ビックリ,0.003464308505789042\\
   不安,心配,0.007884487508311963\\
   期待,ドキドキ,0.005787595254171891\\
   平静,購入,0.01479337514069786\\
\end{itembox}


  \subsection{確率付き顔文字辞書の構築}\label{sec:kaomojidic}
Twitter API を用いて収集した tweet をもとに、顔文字付き感情確率辞書を作成する。
顔文字付き感情確率辞書とは、\ssref{sec:tweetcorpus}で作成した確率付き感情語辞書に、tweet の文中に出現する顔文字を付与した辞書である。

まず、確率付き顔文字辞書を構築する手順を\fref{fig:kaomoji}に示す。

\begin{figure}[h]
  \includegraphics[scale=0.4]{kaomoji.png}
  \caption{確率付き顔文字辞書の構築手順}
  \label{fig:kaomoji}
\end{figure}

ここではまず Tweet 文に対して前処理を行った。それは、不要な文の削除や、顔文字の精査、またRetweetなどの複数のTweet文が合わさったTweet文の分解などである。これは確率付き顔文字辞書の精度を上げるためである。
次に「文」と「顔文字」に分ける。そして文を形態素解析し、確率付き感情語辞書を参照して感情推定を行う。
このときの感情推定では、ナイーブベイズ分類を用いる。
最後にナイーブベイズ分類で求められた感情属性値と各感情における事後確率、そして顔文字を顔文字辞書に登録する。
これらの処理により確率付き顔文字辞書を構築する。
以下ではこれらの手順の詳細を説明する。

まず前処理であるが、最初にRetweetの分解である。Twitterには「Retweet」や「返信」といった機能があり、複数人の文章が一つのTweet文に含まれる場合がある。このとき、それらの文章間には感情の深い関連はないと考えられるため、それぞれの文章へ分割する。例えば以下のようなTweet文があった。

\begin{itembox}{Tweet 文の例}
    良かったら繋がりませんか？(*´ч ` *)RT @mosa2go: 小町かわいい、万里花もかわいい！！！
  \end{itembox}

  これはユーザー「@mosa2go」がTweetした「小町かわいい、万里花もかわいい！！！」に対する返信である。従ってこのTweet文は次のように2つに分割される。

  \begin{itembox}{分割した Tweet 文の例}
    良かったら繋がりませんか？(*´ч ` *) \\
    小町かわいい、万里花もかわいい！！！
  \end{itembox}

  このとき二つ目の文章には顔文字が存在しない。よってこの文章は削除しなければならない。

  次に顔文字の精査を行った。
  簡単には、「顔文字でない可能性があるものを削除する」ことである。
  本研究では「顔文字を含んでいそうなTweet文」を集めたが、その方法は顔文字に相当するような正規表現に適合するかどうかである。
  その正規表現は以下のものを使用している。
  \begin{itembox}{Tweet収集に使用した顔文字の正規表現}
      \begin{verbatim*}
/(\([^\p{Han}\p{Hiragana}\p{Katakana}\p{Digit}(]+?\))/
      \end{verbatim*}
  \end{itembox}
  
  この正規表現の意味は「`('から始まり、顔文字に使えそうな文字が続き、そして`)'で終わるもの」である。つまり現在では「(～～～)」が顔文字候補としてTweet文が収集されている。従って以下のようなTweet文も誤って収集されてしまう。
  \begin{itembox}{Tweet 文の例}
  1.名前 2.電話番号3.住所4.会員番号(FCに入会している場合)5.要望をハガキで。無記名の場合…
  \end{itembox}

  この方法を使用している理由は、1)正確に顔文字のみに一致するような正規表現は作成不可能、2)大量なTweet文を収集するため複雑な処理をその都度行うことが困難、ということが上げられる。

  顔文字の精査には簡単な方法を採った。それは「その顔文字候補の文字列」が「2回以上出現しているか」である。つまり複数回出現するような「(～～～)」は顔文字としてユーザーが使用している可能性が高い。よってそのようなものを含むTweet文を選び出した。

  
  次に確率付き感情語辞書を用いて、前処理した Tweet 文の感情推定を行う。ある Tweet 文を $s_i$、それに含まれる形態素を $w^i_k$、顔文字を $f^i$ とする。すると$s_i$は以下の用に表すことができる。

\[
s_i=w^i_1,w^i_2,\ldots,w_n^i,f^i
\]

本研究で用いる感情は、`喜'、`悲'、`怒'、`驚'、`期待'、`不安'、`平静'の7感情であった。
そこで同様に、7感情を$c_1, c_2, \ldots, c_7$ と表す。

Tweet 文 $s_i$ の感情推定のため、以下のような表を生成する。

\begin{eqnarray*}
  \begin{array}{r|ccc|l}
        & w^i_1        & \ldots          & w^{i}_{n}    & 感情確率 \\ \hline
    c_1 & P(c_1|w^i_1) &                 & P(c_1|w^i_n) & P(c_1) \cdot \prod_{r=1}^{n}P(c_1|w^i_r) \doteq P^i_{c_1}\\
 \vdots &              & \ddots          &              & \\
    c_7 & P(c_7|w^i_1) &                 & P(c_7|w^i_n) & P(c_7) \cdot \prod_{r=1}^{n}P(c_7|w^i_r) \doteq P^i_{c_7}\\
  \end{array}
\end{eqnarray*}

これはナイーブベイズ分類の式を計算する過程である。
このようにしてナイーブベイズ推定からそれぞれの感情確率を求め、それが最大になるような感情をTweet文の感情とする。
そうしてTweet文の感情が推定されたとき、その感情を顔文字$f_i$が表す感情とした。

合わせて、本研究では表の感情確率の列の値を「顔文字感情確率ベクトル」と呼ぶ。これは、「その文が各感情に対してどの程度属するか」を表すものである。
つまり「今日は天気が良いけれど気は重い」のような「楽しい」とも「悲しい」とも言えない微妙な感情の情報を持っている。よって微妙な感情の推定に役立てられる。
そこで本研究では、この感情ベクトルも顔文字を付与する際に用いる。

以上により、「顔文字、推定された感情属性、推定された感情属性の感情確率、顔文字感情確率ベクトル」を、確率付き顔文字辞書へ以下のように登録する。

\begin{eqnarray*}
  \left\{
   \begin{array}{c}
     f^i, \hat{c}, P^i_{\hat{c}}, (P^i_{c_1}, P^i_{c_2}, \ldots, P^i_{c_7})\\
     \vdots \\
     f^j, \hat{c}', P^j_{\hat{c}'}, (P^j_{c_1}, P^j_{c_2}, \ldots, P^j_{c_7})\\
   \end{array}
  \right\}
\end{eqnarray*}

このようにして作成した確率付き顔文字辞書の例を以下に示す。

\begin{itembox}[l]{確率付き顔文字辞書の例}
\verb|(^○^)|,喜,6.074e-116,6.074e-116,3.0684e-118,1.376e-119,1.493e-118,1.380e-118,9.310e-120,6.543e-125\\
\verb|(；▽；)|,悲,2.093e-182,8.68e-185,2.093e-182,6.725e-187,1.920e-186,2.223e-186,1.52e-185,1.587e-202\\
\verb|(´・ω・`)|,不安,4.031e-08,3.044e-08,3.472e-08,1.731e-08,1.731e-08,2.699e-08,4.031e-08,1.731e-08\\
\end{itembox}

\section{顔文字自動付与システム}
本研究では、入力文の感情推定を行い、その文の感情に適切な顔文字を文末に付与するシステムを構築した。
このシステムを「顔文字自動付与システム」と呼ぶ。%名前つける？検討。Auto Recomendation Emoticon System
このシステムでは、\sref{sec:system}\ssref{sec:tweetcorpus}で作成した確率付き感情語辞書と、\sref{sec:system}\ssref{sec:kaomojidic}で作成した確率付き顔文字辞書を用る。

そこでまず、顔文字自動付与システムの処理の概要を以下に示す。

\begin{enumerate}
  \item 入力文を形態素解析する。
  \item 出力された形態素(動詞、名詞、形容詞、感動詞)を使い、ナイーブベイズ分類を用い、確率付き感情語辞書を参照して取り出す。
  \item 確率付き感情語辞書と顔文字付き確率感情語辞書の感情ベクトルのハミング距離を計算する。
  \item ハミング距離が最も小さい顔文字を入力文の文末に付与する。この際、ハミング距離が同等の顔文字が複数個あった場合には、顔文字をランダムに取り出す。
\end{enumerate}

入力文から出力された感情に対応する顔文字を選定する際、顔文字辞書を参照する。
しかし、この顔文字辞書には大量の顔文字が登録されているため、最も適切な1つを選ぶことは難しい。
また、ランダムに1つの顔文字を選び出せば、顔文字推薦の精度が低下するという問題が発生する。

そのため、顔文字辞書の中で最もツイートに適切な顔文字を選ぶ方法として、ハミング距離 (Hamming distance) を用いた手法を提案する。
ハミング距離とは、任意の2つの値を比較したときに値が異なっているビット数の割合である。
また、ハミング距離は、ある文字列を別の文字列に変形する際に必要な置換回数を計測したものである。
1011101 と 1001001 という文字列があった場合、これらの文字列のハミング距離は 2 である。

本研究では、確率付き感情語辞書を用いて入力文の形態素の感情ベクトルを算出し、顔文字付き確率辞書中の感情ベクトルとのハミング距離が最も小さい顔文字を入力文の文末に付与する。
ハミング距離が小さいほど、入力文に対して適切な顔文字を推薦できると考えた。
$f$ を顔文字、$a$ を顔文字付き確率辞書の感情ベクトル、$b$ を入力文の感情ベクトルとしたとき、ハミング距離は以下のように計算する。

\[
  f=\sum_{i=1}^{n} |a_i-b_i|
\]

例えば入力文が「映画最高だった！」である場合、出力される感情は`喜'である。
この文のうち、最も感情確率が高い形態素は「最高」であり、感情確率の値は0.001598であった。
次に顔文字辞書を参照し、この値と最もハミング距離が小さい顔文字を選ぶ。
このとき、ハミング距離の値が同じ顔文字が複数個あった場合にはランダムに顔文字を選ぶ。
そして、入力文の文末に顔文字を付与する。
この例文を入力した際、付与された顔文字は「\verb|(*^o^*)|」であった。

\section{顔文字自動付与システムの実験}\label{sec:experiment}
本研究で構築した顔文字自動付与システムの精度を検証するため、被験者に感情が生起している文章を入力してもらった。
これを被験者5名に1つの感情カテゴリについて5文ずつ、7感情分を入力してもらい、計175文で実験を行った。

入力文に対して推薦された顔文字が適切であれば正解、適切でなければ不正解とし、正解率を求めた。
この正解率を感情推薦システムの精度とする。
精度の計算は、各感情カテゴリごとに、入力文に対して出力された顔文字が適切であると判断された割合の乗数を求めた。
さらに、全カテゴリ分の乗数を掛け合わせ、顔文字自動付与システムの精度とした。
以下に精度の計算式を示す。

\[
  精度=\frac{感情カテゴリごとの付与顔文字の正解数}{感情カテゴリごとの入力文数} \times 7感情 \times 5人
\]

各入力文とその正解感情の例を以下に示す。

\begin{itembox}[l]{正解感情付きの入力文の例}
昨日のラーメンがおいしかった。 喜 \\
高級豆安く手に入って嬉しい！ 喜\\
チャーシューが柔らかかった。 喜\\
この年になると二日酔いが辛い。 悲\\
この服はあまりかわいくない。 悲\\
カフェのランチじゃ物足りない。 悲\\
届いた靴が意外と大きかった…。 悲\\
東京の物件どれも高い。 怒\\
高速バスは危ない！ 怒\\
安い物件はよくないのばかり。 怒\\
卒論がめんどくさい！ 怒\\
Amazon Prime Now で注文したら本当に1時間で届いた！ 驚\\
電車が5分に一回はくるのがすごい！ 驚\\
早く春になってほしい！ 期待\\
バーベキューしたい。 期待\\
在庫が残り少なくなってる。 不安\\
ズボンが入りづらい。 不安\\
雪が降ると寒いね。 平静\\
おはよう。 平静\\
めっちゃねむい。 平静\\
\end{itembox}

精度検証実験の結果、システムの精度は 84.0\%であった。
本研究の顔文字出力システムを用いた出力結果を以下に示す。

\begin{itembox}[l]{出力された顔文字と感情の例}
  昨日のラーメンがおいしかった。 \verb|(*´∀｀*), 喜| \\
高級豆安く手に入って嬉しい！ \verb|( *´v`* ), 喜| \\
チャーシューが柔らかかった。\verb|(*´∀｀*), 喜|\\
この年になると二日酔いが辛い。\verb|(´・_・`), 不安|\\
この服はあまりかわいくない。\verb|('∀'), 悲|\\
カフェのランチじゃ物足りない。\verb|(・_・), 悲|\\
届いた靴が意外と大きかった…。\verb|('A`), 悲|\\
東京の物件どれも高い。\verb|( ・ω・), 悲|\\
高速バスは危ない！\verb|(T ^ T), 怒|\\
安い物件はよくないのばかり。\verb|(´・ω・`), 不安|\\
卒論がめんどくさい！\verb|( 'ω' ), 怒|\\
Amazon Prime Now で注文したら本当に1時間で届いた！ \verb|(*^o^*), 喜|\\
電車が5分に一回はくるのがすごい！\verb|(＠⌒ー⌒＠), 喜|\\
早く春になってほしい！ \verb|(o^∀^o), 期待|\\
バーベキューしたい。\verb|(つд⊂), 期待|\\
在庫が残り少なくなってる。 \verb|(@￣∀￣), 不安|\\
ズボンが入りづらい。\verb|(^_^;), 悲|\\
雪が降ると寒いね。\verb|(^_^), 平静|\\
おはよう。\verb|(*´∀｀), 平静|\\
めっちゃねむい。\verb|(´・皿・`), 平静|\\
\end{itembox}

また、各感情カテゴリの正解率を以下に示す。

\begin{table}
  \caption{各感情カテゴリの正解率}
  \centering
  \begin{tabular}{|c|c|} \hline
    感情カテゴリ & 正解率 \\ \hline \hline
    喜 & 96\% \\ \hline
    悲 & 92\% \\  \hline
    怒 & 68\% \\ \hline
    驚 & 64\% \\ \hline
    不安 & 80\% \\ \hline
    期待 & 92\% \\ \hline
    平静 & 96\% \\ \hline
  \end{tabular}
\end{table}


本研究には、以下の4つの問題点があることが分かった。

\begin{itemize}
  \item 出力された感情と顔文字が表す感情が一致していない。
  \item 若者言葉を含む入力文の感情推定がうまくできていない。
  \item 感情語辞書の登録語数が、感情カテゴリによって偏りがある。
  \item 逆接を表す接続詞を考慮していない。
  \end{itemize}

まず、文から出力された感情と、それに対して付与された顔文字が一致していないという問題である。
本研究では、確率付き感情語辞書を用いて文の感情を推定し、顔文字付き確率感情語辞書を用いて推定した感情に適切な顔文字を入力文に付与する。
しかし、顔文字付き確率辞書に登録された顔文字が感情に適切ではないことが原因で、入力文の感情に不適切な顔文字を付与してしまうことがある。
適切な顔文字の付与に失敗した例を以下に示す。

\begin{table}[htb]
  \centering
  \begin{tabular}{c||c|c} \hline
    入力文 & 推定された感情 & 推薦された顔文字 \\ \hline
    インターネットが繋がらない & 悲 & \verb|( ^ω^)| \\
    本当に腹がたつ & 怒 & \verb|(*´・ω・)|   \\
    明日が楽しみ & 期待 & \verb|(^o^;)| \\ \hline
  \end{tabular}
\end{table}

例えば、「インターネットが繋がらない」という文を形態素解析し、感情語辞書を参照すると、「繋がる」と「ない」の感情確率を取り出す。
これらの感情確率から最も値が大きいものを取り出すと、この文の感情は`悲'となる。
しかし、推薦された顔文字は「\verb|( ^ω^)|」であった。
この顔文字は、目のパーツから推測すると、`喜'の感情に分類されると考えられる。
このように、`悲'の感情属性の文に`喜'の顔文字を付与することは、顔文字自動付与システムの精度が低くなる要因となる。

この問題を解決するために、高島 \ibcite{takashima} の研究を参考に、顔文字解析を行う必要があると考えた。
高島は、Ptaszynski らによって構築された顔文字解析システム CAO のアルゴリズムを参考にし、顔文字の感情推定を行った。
このシステムでは、顔文字の目や口のパーツに着目して感情推定を行い、「喜び」、「悲しみ」、「怒り」、「驚き」の4感情ごとに顔文字をデータベースに登録した。
本研究においても、CAO のアルゴリズムを参考にし、顔文字の目や口のパーツやその位置に着目し、顔文字それぞれの感情を推定する必要がある。
そして、ナイーブベイズ分類を用いて顔文字がある感情に属する確率を算出することで、感情に不適切な顔文字が推薦される問題は少なくなると考える。

問題点の2つめは、若者言葉が出現した際の感情抽出の失敗についてである。
現在、Twitter をはじめとする SNS では「やばい」や「ウケる」など、多くの若者言葉が用いられている。
しかし、感情語辞書の元となった感情コーパスは amazon の商品レビューを元に作られており、ここでは年齢層の違いから若者言葉が用いられていない。
そのため、感情を表す形態素が若者言葉であった場合に、若者言葉は未知語となり、文の感情を正しく推定できないという問題が発生する。
例えば、「窓からレインボーブリッジ見えてまじやばい！」という文がある。
これは、「窓からレインボーブリッジが見えることに感動している」という文である。
しかし、感情を表していると言える「やばい」という単語は感情語辞書に登録されていないため、この例文の感情は無感情となる。

この問題に対して、松本らの感情推定における若者言葉の影響 \ibcite{wakamono} の研究が行われた。
この研究では、Weblog から若者言葉を含む文を自動収集し、手動で若者感情コーパスを構築した。
そして、MeCab を用いて形態素解析し、感情語辞書を用いて抽出した単語に感情をタグ付けした。
このとき、文中に現れる顔文字も抽出し、顔文字辞書を用いて顔文字に感情をタグ付けした。
最後に、感情語と顔文字を SVM とナイーブベイズ分類を用いて学習させた。
本研究でも、この研究を参考にし、若者言葉を含む感情コーパスを構築する必要がある。

また、感情コーパスに入力文を自動で追加し、感情コーパスを更新していくことで若者言葉を学習させることができると考えた。
このとき、形態素解析をする上で、若者言葉をうまく品詞分類できないことがある。
そこで、MeCab に内臓される辞書に手動で若者言葉を登録することで、若者言葉の形態素解析が正しく行われると考える。

問題の3つめは、感情語辞書の偏りである。
全ての感情カテゴリの中で、`喜'と`平静'の正解率が最も高く、96\%であった。
しかし、`驚'の正解率は最も低く、64\%であった。
このように、正解率に大きく差が出た原因は、顔文字付き確率感情辞書の登録語数にあると考える。
顔文字付き感情語辞書の全登録語数は 69700語 である。
各カテゴリの登録語数を以下に示す。

\begin{table}[ht]
  \caption{各カテゴリの登録語数}
\centering
\begin{tabular}{c|c} \hline
  感情カテゴリ & 登録語数 \\ \hline \hline
  喜 & 26942 \\ \hline
  悲 & 11165 \\ \hline
  怒 & 6755 \\ \hline
  驚 & 3153 \\ \hline
  不安 & 3077 \\ \hline
  期待 & 5091 \\ \hline
  平静 & 13513 \\ \hline
\end{tabular}
\end{table}

このように、`喜'の登録語数と、`驚'の登録語数には大きく差がある。
`驚'の感情カテゴリの正解率が低かった原因は、Twitter への `驚' の感情の Tweet が少なかったことが原因であると考えた。
そこで、各感情カテゴリの登録語数のばらつきを減らすことで、精度を高めることができると考えられる。

問題の4つめは、文の逆接を考慮していないという問題である。
例えば、「怒られてばかりでしたが、演奏会は成功しました。」という文がある。
この文を形態素解析すると以下のようになる。

\begin{itembox}[l]{形態素解析の例}
  怒ら  動詞,自立,*,*,五段・ラ行,未然形,怒る,オコラ,オコラ\\
  れ  動詞,接尾,*,*,一段,連用形,れる,レ,レ\\
  て  助詞,接続助詞,*,*,*,*,て,テ,テ\\
  ばかり  助詞,副助詞,*,*,*,*,ばかり,バカリ,バカリ\\
  でし  助動詞,*,*,*,特殊・デス,連用形,です,デシ,デシ\\
  た  助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\\
  が  助詞,接続助詞,*,*,*,*,が,ガ,ガ\\
  、  記号,読点,*,*,*,*,、,、,、\\
  演奏  名詞,サ変接続,*,*,*,*,演奏,エンソウ,エンソー\\
  会  名詞,接尾,一般,*,*,*,会,カイ,カイ\\
  は  助詞,係助詞,*,*,*,*,は,ハ,ワ\\
  成功  名詞,サ変接続,*,*,*,*,成功,セイコウ,セイコー\\
  し  動詞,自立,*,*,サ変・スル,連用形,する,シ,シ\\
  まし  助動詞,*,*,*,特殊・マス,連用形,ます,マシ,マシ\\
  た  助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\\
  。  記号,句点,*,*,*,*,。,。,。\\
  EOS
\end{itembox}

この文を顔文字自動付与システムに与えると、「怒」の感情が出力された。
この原因として、「怒る」という単語の感情確率が最も大きかったことが考えられる。
この問題を解決するために、Cabocha \ibcite{cabocha}を用いた係り受け解析がある。

係り受け解析とは、文法規則によって、文の構造を句・文節を単位として解析することである。
句とは、2つ以上の語が集まって1つの品詞と同じような働きをしながら、文を構成する語の塊のことである。
名詞の役割を果たす句を名詞句 (NP)、動詞の役割を果たす句を動詞句 (VP) とするように、形容詞句(ADJP)、副詞句(ADVP)などがある。
英語では句構造で構文解析を行うが、日本語の場合は、文節を単位に係り受け関係を用いて構文を解析するのが一般的である。
文節とは、日本語を意味の分かる単位で区切ったものである。
日本語においては、文における任意の1つの文節は少なくともその文節の後の１つの文節と係り受け関係を持つ特徴がある。

係り受け解析の例を以下に示す。

\begin{itembox}[l]{係り受け解析結果}
  * 0 2D 0/6 -3.060093 \\
  怒ら  動詞,自立,*,*,五段・ラ行,未然形,怒る,オコラ,オコラ \\
  れ  動詞,接尾,*,*,一段,連用形,れる,レ,レ\\
  て  助詞,接続助詞,*,*,*,*,て,テ,テ\\
  ばっかり  助詞,副助詞,*,*,*,*,ばっかり,バッカリ,バッカリ\\
  でし  助動詞,*,*,*,特殊・デス,連用形,です,デシ,デシ\\
  た  助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\\
  が  助詞,接続助詞,*,*,*,*,が,ガ,ガ\\
  、  記号,読点,*,*,*,*,、,、,、\\
  * 1 2D 1/2 -3.060093\\
  演奏  名詞,サ変接続,*,*,*,*,演奏,エンソウ,エンソー\\
  会  名詞,接尾,一般,*,*,*,会,カイ,カイ\\
  は  助詞,係助詞,*,*,*,*,は,ハ,ワ\\
  * 2 -1D 1/3 0.000000\\
  成功  名詞,サ変接続,*,*,*,*,成功,セイコウ,セイコー\\
  し  動詞,自立,*,*,サ変・スル,連用形,する,シ,シ\\
  まし  助動詞,*,*,*,特殊・マス,連用形,ます,マシ,マシ\\
  た  助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\\
  。  記号,句点,*,*,*,*,。,。,。\\
  EOS
\end{itembox}

CaboCha では、形態素解析と共に文節の係り受け関係を解析している。
* から始まる業には文節の係り受け関係が示されており、形態素は行ごとに区切られている。
* の右隣の数字は文節番号を表し、その右横にはその文節が係る文節番号が示されている。
係る文節番号が -1D であった場合、その文節はどの文節にも係っていないことを示す。
この係り受け解析を利用することで、`怒る'という単語が `成功' に係っていることが分かるため、感情属性を付与することができると考えられる。
また、係り受け解析を用いれば文の述部が分かるので、述部の感情に重み付けすることができる。

\section{まとめ}\label{sec:summary}
  %考察と原因の解明
本研究は、感情語辞書と顔文字辞書を用いて、入力文から感情を推定し適切な顔文字を自動で付与するシステムを提案した。
\sref{sec:begin}では、本研究の背景と目的を述べた。背景には、スマートフォンの台頭に併せて SNS が普及し、そこでは短文で即応性のあるやりとりがされていることがある。
そして、SNS のユーザは、文の感情を強調・補足するために、絵文字を多く利用する。
そこで、SNS でのコミュニケーションをより円滑にするために、文の感情を推定して自動で顔文字を付与することを本研究の目的とした。
\sref{sec:relatedworks}では、本研究を行う上で参考にした、感情推定及び顔文字推薦に関する文献・論文について述べた。
感情推定には、感情語辞書を用いる手法と、感情コーパスを用いる手法がある。
そして、これらを構築する手段として、ナイーブベイズ分類や SVM を使用して感情確率値を計算する方法があることが分かった。
また、顔文字推薦には、CAO システムのような顔文字の感情解析システムを用いる手法があることが分かった。
\sref{sec:tools}では、感情推定における自然言語処理の基礎技術を説明した。
まず、Twitter から tweet を大量に取得するための Twitter API について述べた。
そして、これを形態素解析するための、MeCab と Natto について述べた。
本研究では、取得した tweet 文を形態素解析し、感情語辞書を構築する。
\sref{sec:def}では、ベイズ推定とナイーブベイズ分類を説明した。
ベイズ推定とは、ベイズの定理に基づき、観測事象からその原因となる事象を確率的に推論する手法である。
また、ナイーブベイズ分類とは、ベイズの定理に基づいて特徴ベクトル間に独立性を仮定した分類手法である。
\sref{sec:system}では、ナイーブベイズ分類を用いて、Twitter から収集した文をもとにした感情語辞書と顔文字辞書の構築手法を述べた。このとき、学習データとして先行研究の感情コーパスを使用した。文中の形態素 $w_i$ が出現した際に、各感情 $e_2,e_2, \cdots ,e_7$ それぞれに帰属する確率を求めた。そして、これらの辞書を用いて入力文の感情を推定し、感情に適切な顔文字を推薦するシステムを提案した。このとき、出力された感情に最も適切な顔文字を選出するため、入力文の感情語と顔文字辞書に登録された感情の感情ベクトルのハミング距離を求め、ハミング距離が最も小さいものを入力文に付与した。
\sref{sec:experiment}では、顔文字自動付与システムの精度を検証するため、5名の被験者に感情生起文を各感情につき5文ずつに入力してもらった。
入力文に対して付与された顔文字が適切であれば正解、適切でなければ不正解とし、正解率を出した。
この正解率を顔文字自動付与システムの精度とした。
この実験の結果、顔文字自動付与システムの精度は 84.0\% であった。
実験結果をもとに、顔文字自動付与システムの問題点とその原因について述べた。
顔文字自動付与システムには4つの問題点があることが分かった。
それは、文から推定される感情と顔文字が一致していないという問題と、未知の若者言葉が感情語として文中に出現した場合に感情を推定できないという問題、感情語辞書に大きな偏りがある問題、そして文中の逆接を考慮していないという問題である。
今後はこれらの問題点を考慮し、さらなる精度向上を目指す必要がある。

 %参考文献ファイル設定
 \clearpage
 \bibliographystyle{ib_plain}
 \bibliography{lastthesisref} %bibファイルネーム
\end{document}
